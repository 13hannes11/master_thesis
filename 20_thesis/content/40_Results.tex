\chapter{Results}
\label{ch:Results}

\todo[inline, caption={}]{
    \begin{itemize}
        \item Shows the findings of the project, often in the form of data.
        \item Comments on those findings which illustrate the significance of the results.
        \item Data Commentary:
        \begin{itemize}
            \item It is important to comment on the visual information, highlighting to your reader what they should notice and why this is important. 
            \item Location statement
            \item Linking as-statement
            \item Highlighting statement: drawing attention to key information.
        \end{itemize} 
    \end{itemize}
}

\section{Focus Distance Measure}
\label{sec:Results:FocusDistance}

When the task is to estimate the distance or offset to the best focus value \acs{poop}-\acs{resnet}-34 performs best, followed by \acs{poop}-\acs{resnet}-101 and \acs{poop}-\acs{resnet}-18 (refer to \autoref{tab:Results:Models:Accuracy}). \Acs{poop}-\acs{resnet}-34 reaches a \ac{mae} of $0.0056$ which is an average error of less than one image in a focus stack (approximately $0.007$). Further the \ac{srcc} and \ac{plcc} are above $0.9$ thereby showing a strong correlation. The \ac{r2} score of $0.86$ supports this as well.

\begin{table}
    \centering
    \caption{Comparing \acs{poop} models on the task of predicting the relative position of the focus plane.}
    \begin{tabular}{|l|rrrr|}
        \hline
        method          & \acs{mae} & \acs{srcc} & \acs{plcc} & \acs{r2} \\
        \hline
        \acs{poop}-\acs{fc}        & 0.0186 & -0.0384 & -0.0242 & -0.2058 \\
        \acs{poop}-\acs{cnn}        & 0.0166 &  0.2436 &  0.2339 &  0.0285 \\
        \acs{poop}-\acs{resnet}-101      & 0.0064 &  0.9177 &  0.9057 &  0.8121 \\
        \acs{poop}-\acs{resnet}-34       & 0.0056 &  0.9386 &  0.9261 &  0.8570 \\
        \acs{poop}-\acs{resnet}-18       & 0.0075 &  0.9014 &  0.8847 &  0.7521 \\
        \hline
    \end{tabular}
    \label{tab:Results:Models:Accuracy}
\end{table}

\autoref{fig:Results:ScatterPredictedTarget} shows the predictions of in comparison to the targeted values when using \acs{poop}-\acs{resnet}-34). The plot shows a line which represents the perfect match between targets and predictions. The data points in the plot clearly follow this line. Predictions in the negative range also mostly correspond to negative targets. Further, some outliers can be seen in the plot which can be found in the plot.


\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{images/40_results/scatter_predictions_targets.pdf}
    \caption{The predictions plotted compared to targets with the ideal drawn as a line (using \acs{poop}-\acs{resnet}-34).}
    \label{fig:Results:ScatterPredictedTarget}
\end{figure}

To give a clearer overview of the predictions also a histogram has been plotted. The histogram in \autoref{fig:Results:HistogramPredictedTarget} shows a fairly similar distribution between ground truth and targets. Of note, however, is that there are no predictions for bins starting at lower than $-0.04$. Further there focus values slightly below zero are not predicted as often and focus values around $-0.03$ and around $0.02$ seem to be predicted disproportionally often especially compared to the ground truth.

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{images/40_results/histogram_predictions_targets.pdf}
    \caption{A histogram showing the distribution of predicted focus compared to annotated focus (using \acs{poop}-\acs{resnet}-34).}
    \label{fig:Results:HistogramPredictedTarget}
\end{figure}


\section{Comparison to Traditional Focus Methods}
\label{sec:Results:TraditionalFocusMethods}

The models are also compared to traditional focus methods. The results of this comparison are shown in \autoref{tab:Results:Comparison:RelatedWorks:Accuracy} and \autoref{tab:Results:Comparison:RelatedWorks:IndexMAE}.

\autoref{tab:Results:Comparison:RelatedWorks:Accuracy} shows the accuracy of models when predicting the correct image of a focus stack.

\autoref{tab:Results:Comparison:RelatedWorks:IndexMAE} on the other hand, shows \ac{mae}$^*$ of the index. This shows that \acs{poop}-\acs{resnet}-18 commonly is off by one image. \todo{write more about the table}. The index difference is also shown in \autoref{fig:Results:Comparison:RelatedWorks:IndexMAE} as a violin plot. \todo{write more about the violin plot}


\begin{table}
    \centering
    \caption{Comparing \acs{poop} to other methods in terms of accuracy of finding the best in-focus image ($\pm 1$) from a focus stack.}
    \begin{tabular}{lrrrrr}
        \hline
        \multicolumn{1}{c}{} & \multicolumn{5}{c}{accuracy} \\
        \cline{2-6}
        method & all & trichuris & ascaris & schistosoma & hookworm \\
        \hline
        \acs{mdct}                      & 0.40 & 0.31 & 0.60 & 0.31 & 0.40 \\
        \acs{vol4}                      & 0.44 & 0.50 & 0.60 & 0.50 & 0.13 \\
        \acs{laplacian}                 & 0.60 & 0.50 & 0.73 & 0.63 & 0.53 \\
        \hline
        \acs{poop}-\acs{fc}             & 0.19 & 0.25 & 0.20 & 0.12 & 0.20 \\
        \acs{poop}-\acs{cnn}            & 0.74 & 0.69 & 0.53 & 0.88 & 0.87 \\
        \acs{poop}-\acs{resnet}-101     & 0.82 & 0.69 & 0.80 & 0.88 & 0.93 \\
        \acs{poop}-\acs{resnet}-34      & 0.90 & 0.94 & 0.87 & 0.94 & 0.87 \\
        \acs{poop}-\acs{resnet}-18      & 0.82 & 0.69 & 0.73 & 0.88 & 1.00 \\ 
    \end{tabular}
    \label{tab:Results:Comparison:RelatedWorks:Accuracy}
\end{table}

\begin{table}
    \centering
    \caption{Comparing \acs{poop} to other methods in terms of \ac{mae} of image indexes compared to the best in-focus image from a focus stack.}
    \begin{tabular}{lrrrrr}
        \hline
        \multicolumn{1}{c}{} & \multicolumn{5}{c}{\ac{mae}$^*$} \\
        \cline{2-6}
        method & all & trichuris & ascaris & schistosoma & hookworm \\
        \hline
        \acs{mdct}      & 2.31 & 2.13 & 1.93 & 2.63 & 2.53 \\
        \acs{vol4}      & 2.23 & 1.88 & 1.80 & 2.13 & 3.13 \\
        \acs{laplacian} & 1.60 & 1.81 & 1.33 & 1.56 & 1.67 \\
        \hline
        \acs{poop}-\acs{fc}              & 3.27 & 3.31 & 3.47 & 3.00 & 3.33 \\
        \acs{poop}-\acs{cnn}             & 1.06 & 1.38 & 1.40 & 0.75 & 0.73 \\
        \acs{poop}-\acs{resnet}-101      & 0.92 & 1.06 & 1.07 & 0.94 & 0.60 \\
        \acs{poop}-\acs{resnet}-34       & 0.65 & 0.63 & 0.80 & 0.56 & 0.60 \\
        \acs{poop}-\acs{resnet}-18       & 0.95 & 1.31 & 0.87 & 1.06 & 0.53 \\
    \end{tabular}
    \label{tab:Results:Comparison:RelatedWorks:IndexMAE}
\end{table}

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{images/40_results/index_diff_to_gt_violin.pdf}
    \caption{Comparing \acs{poop} to other methods in terms of \ac{mae}$^*$ of image indexes compared to the best in-focus image from a focus stack. The same data is represented in \autoref{tab:Results:Comparison:RelatedWorks:IndexMAE}.}
    \label{fig:Results:Comparison:RelatedWorks:IndexMAE}
\end{figure}


\section{Heatmap and Stitched Image Generation}
\label{sec:Results:HeatStiched}

\begin{figure}
    \centering
    \begin{subfigure}[b]{\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/40_results/heatmap_legend.pdf}
    \end{subfigure}
    \begin{subfigure}[b]{0.5\textwidth}
        \centering
        \caption{stack index 3}
        \includegraphics[width=\textwidth]{images/40_results/heatmap_layer_3.pdf}
        \label{fig:Results:Stack:HeatMap:Stack3}
    \end{subfigure}%
    \begin{subfigure}[b]{0.5\textwidth}
        \centering
        \caption{stack index 4}
        \includegraphics[width=\textwidth]{images/40_results/heatmap_layer_4.pdf}
        \label{fig:Results:Stack:HeatMap:Stack4}
    \end{subfigure}
    \par
    \begin{subfigure}[b]{0.5\textwidth}
        \centering
        \caption{stack index 5}
        \includegraphics[width=\textwidth]{images/40_results/heatmap_layer_5.pdf}
        \label{fig:Results:Stack:HeatMap:Stack5}
    \end{subfigure}%
    \begin{subfigure}[b]{0.5\textwidth}
        \centering
        \caption{stitched image}
        \includegraphics[width=\textwidth]{images/40_results/heatmap_stiched.pdf}
        \label{fig:Results:Stack:HeatMap:Stiched}
    \end{subfigure}
    \caption{Figure comparing the heatmap of images of a focus stack to a generated image based on the focus prediction model (\acs{poop}-\acs{resnet}-34).}
    \label{fig:Results:Stack:HeatMap}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{images/40_results/focus_stack_contour_plot.pdf}
    \caption{Contour plot showing which image of the focus stack is most in focus according to the model (\acs{poop}-\acs{resnet}-34).}
    \label{fig:Results:Stack:ContourPlot}
\end{figure}

\begin{figure}
    \centering
    \begin{subfigure}[b]{\textwidth}
        \centering
        \caption{stack index: 4}
        \includegraphics[width=\textwidth]{images/40_results/focus_stack_4.jpg}
        \label{fig:Results:Stack:SideBySide:Index0}
    \end{subfigure}
    \begin{subfigure}[b]{\textwidth}
        \centering
        \caption{stack index: 5}
        \includegraphics[width=\textwidth]{images/40_results/focus_stack_5.jpg}
        \label{fig:Results:Stack:SideBySide:Index1}
    \end{subfigure}
    \begin{subfigure}[b]{\textwidth}
        \centering
        \caption{stack index: 6}
        \includegraphics[width=\textwidth]{images/40_results/focus_stack_6.jpg}
        \label{fig:Results:Stack:SideBySide:Index2}
    \end{subfigure}
    \begin{subfigure}[b]{\textwidth}
        \centering
        \caption{stitched image}
        \includegraphics[width=\textwidth]{images/40_results/focus_stack_stiched.png}
        \label{fig:Results:Stack:SideBySide:Stiched}
    \end{subfigure}
    \caption{Comparison of images from the focus stack to a generated combined image based on the focus prediction of the model (\acs{poop}-\acs{resnet}-34).}
    \label{fig:Results:Stack:SideBySide}
\end{figure}

\section{Speed and Memory Consumption}
\label{sec:Results:Computation}

This section is detailing the hardware needed to run each model. Traditional methods need the least amount of memory and overall are the fastest. \Acl{nn} models, need the most additional memory and the memory and computation time increases with model size. 


\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{images/40_results/speed.pdf}
    \caption{The mean speed of processing a patch by model on the \ac{cpu} and \ac{gpu}.}
    \label{fig:Results:Computation:Speed}
\end{figure}

\begin{table}[ht]
    \centering
    \caption{Comparison of model speed for processing a single patch in milliseconds on the \ac{cpu} and \ac{gpu}.}
    \label{tab:Results:Computation:Speed}
    \begin{tabular}{@{\extracolsep{6pt}}lrrrrrr@{}}
        \hline
        \multicolumn{1}{c}{} & \multicolumn{2}{c}{median} & \multicolumn{2}{c}{mean} & \multicolumn{2}{c}{std} \\
        \cline{2-3}\cline{4-5}\cline{6-7}
        name & \acs{gpu} & \acs{cpu} & \acs{gpu} & \acs{cpu} & \acs{gpu} & \acs{cpu} \\
        \hline
        \acs{mdct}                      & 0.17 &  0.40 & 0.18 &  0.41 & 0.02 & 0.06 \\
        \acs{vol4}                      & 0.11 &  0.18 & 0.11 &  0.18 & 0.01 & 0.01 \\
        \acs{laplacian}                 & 0.19 &  0.43 & 0.19 &  0.44 & 0.01 & 0.03 \\
        \hline
        \acs{poop}-\acs{fc}             & 0.31 &  1.67 & 0.31 &  1.68 & 0.02 & 0.06 \\
        \acs{poop}-\acs{cnn}            & 0.26 &  1.46 & 0.27 &  1.49 & 0.02 & 0.10 \\
        \acs{poop}-\acs{resnet}-101     & 8.98 & 75.54 & 8.86 & 77.06 & 0.48 & 9.43 \\
        \acs{poop}-\acs{resnet}-34      & 3.09 & 34.02 & 3.19 & 33.61 & 0.29 & 5.44 \\
        \acs{poop}-\acs{resnet}-18      & 1.73 & 19.91 & 1.78 & 19.27 & 0.23 & 2.94 \\
    \end{tabular}
\end{table}

\todo[inline]{
    N is number of pixels
    Space usage:
    VOL4: $O(1) =>$ Store sum 
    
    MDCT: $O(1) =>$ Store sum; For convolution store in tmp variable and do addition and later potentiation.
    
    ML: Same for mean laplacian: or convolution store in tmp variable and do addition
    
    ML: models: $O(N) => maximum(channels * input\_size^2) + model\_size $
}

\todo[inline, caption={}]{
    add table with:
    \begin{itemize}
        \item model size (measured)
        \item memory usage during prediction (theory)
        \item memory usage during prediction O(notation)
        \item Potentially (speed as O notation)
    \end{itemize}
}

\begin{table}[ht]
    \centering
    \caption{Additional memory usage by each model.}
    \label{tab:Results:Computation:Memory}
    \begin{tabular}{lr}
        \hline
        name & model size (MiB) \\
        \hline
        \acs{poop}-\acs{fc}         &  33.2 \\
        \acs{poop}-\acs{cnn}        &   0.8 \\
        \acs{poop}-\acs{resnet}-101 & 162.9 \\
        \acs{poop}-\acs{resnet}-34  &  82.8 \\
        \acs{poop}-\acs{resnet}-18  &  43.4 \\
    \end{tabular}
\end{table}



\todo[inline]{
    CPU:
    microscopes: Jetson Nano: ARM Cortex-A57 4 Core 1479 MHz (cpubenchmark: 400 (single-thread), 947 (multi))
    egghead: Ryzen 5 2600X: 2406 (single), 14050 (multicore) 
    rasberry pi 4: 569 (single), 853 (multi)

    \url{https://www.cpubenchmark.net/compare/ARM-Cortex-A57-4-Core-1479-MHz-vs-AMD-Ryzen-5-2600X-vs-ARM-Cortex-A72-4-Core-1800-MHz/3914vs3235vs4078}

    GPU:
    microscopes: Jetson Nano: 236 GFLOPS (FP32)
    egghead: RTX 2070: 7465 GFLOPS (FP32) 
    rasberry pi 4: -

    \url{https://www.techpowerup.com/gpu-specs/jetson-nano-gpu.c3643}
    \url{https://www.techpowerup.com/gpu-specs/geforce-rtx-2070.c3252}

    Add estimated performance for different hardware/model combinationshttps://www.techpowerup.com/gpu-specs/jetson-nano-gpu.c3643
}
