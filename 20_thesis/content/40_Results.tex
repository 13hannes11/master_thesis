\chapter{Results}
\label{ch:Results}

\todo{Introduction to results chapter}

\todo[inline, caption={}]{
    \begin{itemize}
        \item Shows the findings of the project, often in the form of data.
        \item Comments on those findings which illustrate the significance of the results.
        \item Data Commentary:
        \begin{itemize}
            \item It is important to comment on the visual information, highlighting to your reader what they should notice and why this is important. 
            \item Location statement
            \item Linking as-statement
            \item Highlighting statement: drawing attention to key information.
        \end{itemize} 
    \end{itemize}
}

\section{Focus Distance Prediction}
\label{sec:Results:FocusDistance}

When the task is to estimate the distance or offset to the best focus value \acs{poop}-\acs{resnet}-34 performs best, followed by \acs{poop}-\acs{resnet}-101 and \acs{poop}-\acs{resnet}-18 (refer to \autoref{tab:Results:Models:Accuracy}). \Acs{poop}-\acs{resnet}-34 reaches a \ac{mae} of $0.0056$ which is an average error of less than one image in a focus stack (approximately $0.007$). Further the \ac{srcc} and \ac{plcc} are above $0.9$ thereby showing a strong correlation. The \ac{r2} score of $0.86$ supports this as well.
The worst performing model is \acs{poop}-\acs{fc} with most metrics lying below $0.04$ except \ac{srcc} with a value of $0.12$. This model shows no direct correlation with the focus input data. The \acs{poop}-\acs{cnn}'s \ac{mae} is only slightly worse than \acs{poop}-\acs{resnet} models. It shows still some good correlation for \ac{srcc} and \ac{plcc}, however the \ac{r2} score is just below $0.70$. 

\begin{table}
    \centering
    \caption{Comparing \acs{poop} models on the task of predicting the relative position of the focus plane.}
    \begin{tabular}{lrrrr}
        \hline
        method          & \acs{mae} & \acs{srcc} & \acs{plcc} & \acs{r2} \\
        \hline
        \acs{poop}-\acs{fc}             & 0.0170 & 0.1154 & 0.0357 & 0.0008 \\
        \acs{poop}-\acs{cnn}            & 0.0085 & 0.8605 & 0.8424 & 0.6911 \\
        \acs{poop}-\acs{resnet}-101     & 0.0064 & 0.9177 & 0.9057 & 0.8121 \\
        \acs{poop}-\acs{resnet}-34      & \underline{0.0056} & \underline{0.9386} & \underline{0.9261} & \underline{0.8570} \\
        \acs{poop}-\acs{resnet}-18      & 0.0075 & 0.9014 & 0.8847 & 0.7521 \\
    \end{tabular}
    \label{tab:Results:Models:Accuracy}
\end{table}

\autoref{fig:Results:ScatterPredictedTarget} shows the predictions of in comparison to the targeted values when using \acs{poop}-\acs{resnet}-34. The plot shows a line which represents the ideal match between targets and predictions. The data points in the plot clearly follow this line, they however have an approximate spread of 0.01 across most predictions. When a target range close to zero is reached the observed vertical spread is larger. Negative predictions also mostly correspond to negative targets. Further, one outlier can be seen with a target value of smaller than $-0.08$ and one with a target value of smaller than $-0.05$. Additional outliers are seen across the whole plot which increase the spread quite substantially.


\begin{figure}
    \centering
    \includegraphics[width=0.5\textwidth]{images/40_results/scatter_predictions_targets.pdf}
    \caption{The predictions plotted compared to targets with the ideal drawn as a line (using \acs{poop}-\acs{resnet}-34).}
    \label{fig:Results:ScatterPredictedTarget}
\end{figure}

\todo[inline]{should I add a second plot of prediction vs targets for cnn? \autoref{fig:Results:ScatterPredictedTarget}}

To give a clearer overview of the predictions also a histogram has been plotted. The histogram in \autoref{fig:Results:HistogramPredictedTarget} shows a fairly similar distribution between ground truth and targets. Of note, however, is that there are no predictions for bins starting at lower than $-0.04$. Further focus values slightly below zero are not predicted as often and focus values around $-0.03$ and around $0.02$ seem to be predicted disproportionally often especially compared to the ground truth. This is consistent with the higher spread observed close to zero in \autoref{fig:Results:ScatterPredictedTarget}.

\begin{figure}
    \centering
    \includegraphics[width=0.5\textwidth]{images/40_results/histogram_predictions_targets.pdf}
    \caption{A histogram showing the distribution of predicted focus compared to annotated focus (using \acs{poop}-\acs{resnet}-34).}
    \label{fig:Results:HistogramPredictedTarget}
\end{figure}

\todo[inline]{should I add a second histogram of prediction vs targets for cnn? \autoref{fig:Results:HistogramPredictedTarget}}

\FloatBarrier

\section{Comparison to Traditional Focus Methods}
\label{sec:Results:TraditionalFocusMethods}

The models are also compared to traditional focus methods. The results of this comparison are shown in \autoref{tab:Results:Comparison:RelatedWorks:Accuracy} and \autoref{tab:Results:Comparison:RelatedWorks:IndexMAE}.

\autoref{tab:Results:Comparison:RelatedWorks:Accuracy} shows the accuracy of models when predicting the correct image ($\pm 1$) of a focus stack. A higher accuracy is a better. Of note is the high accuracy when using \ac{mdct}. In overall accuracy \ac{mdct} beats all other traditional methods with a large margin. Further it reaches a higher result than all neural network based models except the best performing \acs{poop}-\acs{resnet}-32. Also, of note should be that of \acs{poop}-\acs{cnn} which reaches an accuracy of $0.71$ and thereby beats most traditional methods (\ac{vol4} and \ac{laplacian}). The worst performing model is \acs{poop}-\acs{fc} followed by \ac{vol4}.

A similar result can be seen in \autoref{tab:Results:Comparison:RelatedWorks:IndexMAE} which, shows \ac{mae}$^*$ of the index. With this metric a lower error shows a better result. The best performing model is \acs{poop}-\acs{resnet}-34 followed by \acs{mdct}. \Acs{mdct} has the lowest error when predicting hookworms, but all other categories are lead by \acs{poop}-\acs{resnet}-34. \Acs{poop}-\acs{resnet}-18 commonly is off by one image with an error of $0.95$. The same data as also visualized in \autoref{fig:Results:Comparison:RelatedWorks:IndexMAE} as a violin plot. The violin plot shows that maximum error for \ac{mdct} is fairly low. Errors of \ac{mdct} where the index is predicted in the negative direction do not exceed an off by minus one. The positive direction however is off to a larger extend. The overall maximum and minimum error of \acs{poop}-\acs{resnet}-34 are in a similar range, however, it is more symmetric. Another characteristic that the plot reveals is that the mean of most metrics is close to zero.


\begin{table}
    \centering
    \caption{Comparing \acs{poop} to other methods in terms of accuracy of finding the best in-focus image ($\pm 1$) from a focus stack.}
    \begin{tabular}{lrrrrr}
        \hline
        \multicolumn{1}{c}{} & \multicolumn{5}{c}{accuracy} \\
        \cline{2-6}
        method & all & trichuris & ascaris & schistosoma & hookworm \\
        \hline
        \acs{mdct}                      & \underline{0.84} & \underline{0.62} & \underline{0.87} & \underline{0.88} & \underline{1.00} \\
        \acs{vol4}                      & 0.31 & 0.38 & 0.47 & 0.31 & 0.07 \\
        \acs{laplacian}                 & 0.60 & 0.50 & 0.73 & 0.62 & 0.53 \\
        \hline
        \acs{poop}-\acs{fc}             & 0.21 & 0.25 & 0.27 & 0.12 & 0.20 \\
        \acs{poop}-\acs{cnn}            & 0.71 & 0.50 & 0.80 & 0.75 & 0.80 \\
        \acs{poop}-\acs{resnet}-101     & 0.82 & 0.69 & 0.80 & 0.88 & 0.93 \\
        \acs{poop}-\acs{resnet}-34      & \underline{0.90} & \underline{0.94} & \underline{0.87} & \underline{0.94} & 0.87 \\
        \acs{poop}-\acs{resnet}-18      & 0.82 & 0.69 & 0.73 & 0.88 & \underline{1.00} \\ 
    \end{tabular}
    \label{tab:Results:Comparison:RelatedWorks:Accuracy}
\end{table}

\begin{table}
    \centering
    \caption{Comparing \acs{poop} to other methods in terms of \ac{mae} of image indexes compared to the best in-focus image from a focus stack.}
    \begin{tabular}{lrrrrr}
        \hline
        \multicolumn{1}{c}{} & \multicolumn{5}{c}{\ac{mae}$^*$} \\
        \cline{2-6}
        method & all & trichuris & ascaris & schistosoma & hookworm \\
        \hline
        \acs{mdct}      & \underline{0.87} & \underline{1.56} & \underline{0.80} & \underline{0.69} & \underline{0.40} \\
        \acs{vol4}      & 2.45 & 1.88 & 2.07 & 2.50 & 3.40 \\
        \acs{laplacian} & 1.60 & 1.81 & 1.33 & 1.56 & 1.67 \\
        \hline
        \acs{poop}-\acs{fc}              & 3.53 & 3.00 & 3.20 & 4.06 & 3.87 \\
        \acs{poop}-\acs{cnn}             & 1.19 & 1.38 & 1.00 & 1.19 & 1.20 \\
        \acs{poop}-\acs{resnet}-101      & 0.92 & 1.06 & 1.07 & 0.94 & 0.60 \\
        \acs{poop}-\acs{resnet}-34       & \underline{0.65} & \underline{0.63} & \underline{0.80} & \underline{0.56} & 0.60 \\
        \acs{poop}-\acs{resnet}-18       & 0.95 & 1.31 & 0.87 & 1.06 & \underline{0.53} \\
    \end{tabular}
    \label{tab:Results:Comparison:RelatedWorks:IndexMAE}
\end{table}

\begin{figure}
    \centering
    \includegraphics[width=0.75\textwidth]{images/40_results/index_diff_to_gt_violin.pdf}
    \caption{Comparing \acs{poop} to other methods in terms of \ac{mae}$^*$ of image indexes compared to the best in-focus image from a focus stack. The same data is represented in \autoref{tab:Results:Comparison:RelatedWorks:IndexMAE}.}
    \label{fig:Results:Comparison:RelatedWorks:IndexMAE}
\end{figure}

\FloatBarrier

\section{Heatmap and Stitched Image Generation}
\label{sec:Results:HeatStiched}

This section contains visualizations of focus stacks and individual images that are all taken from the same focus stack. One image of this focus stack is shown in \autoref{fig:Results:Stack:ImageSliceVisualisation}. Later, \autoref{fig:Results:Stack:SideBySide} shows slices of different images of the same focus stack. \autoref{fig:Results:Stack:ImageSliceVisualisation} describes where from the slices are taken. The image shown has the stack index 4.

\begin{figure}
    \centering
    \includegraphics[width=0.6\textwidth]{images/40_results/image_slice_visualisation.pdf}
    \caption{Visualization of focus stack of image slide and the image slice taken from the image.}
    \label{fig:Results:Stack:ImageSliceVisualisation}
\end{figure}


To get an overview of different focus levels different image slices of a focus stack are shown in \autoref{fig:Results:Stack:SideBySide}. The slice of the image contains one egg. The egg is most in focus in the slice with stack index 4 (\autoref{fig:Results:Stack:SideBySide:Index0}). On the other hand \autoref{fig:Results:Stack:SideBySide:Index2} shows the background most clear. This illustrates the different focus planes of background and focus image. A mosaic image that was produced using \acs{poop}-\acs{resnet}-34 is shown in \autoref{fig:Results:Stack:SideBySide:Stiched}. The mosaic or stiched image mostly leaves the background unfocused, however, some features like a stone (right and upwards of the egg) are shown in focus. Further the egg seems to stem mostly from the image with index 5 (\autoref{fig:Results:Stack:SideBySide:Index1}). Of note is also, that the picture is produced based on the whole focus stack, not only the images shown.


\begin{figure}
    \centering
    \begin{subfigure}[b]{\textwidth}
        \centering
        \includegraphics[width=0.6\textwidth]{images/40_results/focus_stack_4.jpg}
        \caption{stack index: 4}
        \label{fig:Results:Stack:SideBySide:Index0}
        \vspace{1em}
    \end{subfigure}

    \begin{subfigure}[b]{\textwidth}
        \centering
        \includegraphics[width=0.6\textwidth]{images/40_results/focus_stack_5.jpg}
        \caption{stack index: 5}
        \label{fig:Results:Stack:SideBySide:Index1}
        \vspace{1em}
    \end{subfigure}

    \begin{subfigure}[b]{\textwidth}
        \centering
        \includegraphics[width=0.6\textwidth]{images/40_results/focus_stack_6.jpg}
        \caption{stack index: 6}
        \label{fig:Results:Stack:SideBySide:Index2}
        \vspace{1em}
    \end{subfigure}

    \begin{subfigure}[b]{\textwidth}
        \centering
        \includegraphics[width=0.6\textwidth]{images/40_results/focus_stack_stiched.png}
        \caption{stitched image}
        \label{fig:Results:Stack:SideBySide:Stiched}
    \end{subfigure}
    \caption{Comparison of a cropped part of images from the focus stack to a generated combined image based on the focus prediction of the model (\acs{poop}-\acs{resnet}-34).}
    \label{fig:Results:Stack:SideBySide}
\end{figure}

The properties of distance prediction allow the generation of a heatmap on a whole image taken by a microscope. \autoref{fig:Results:Stack:HeatMap} shows a heatmap generated using \acs{poop}-\acs{resnet}-34 on different images of a focus stack. The heatmaps for the images with the index $3$, $4$ and $5$ are shown in \autoref{fig:Results:Stack:HeatMap:Stack3}, \autoref{fig:Results:Stack:HeatMap:Stack4} and \autoref{fig:Results:Stack:HeatMap:Stack5} respectively. Areas predicted to be in focus are shown in white, areas shown in red are predicted to be off the focus plane in the negative direction and areas in blue in the positive direction. The image with index 3 is dominated by mostly red areas however, some areas are also coloured light blue and therefore seem to be fairly close to the focal plane. When comparing this to the image with index 4, it is noticeable that the blue coloured areas are darker, thereby showing that they are further away from the ideal focus plane. The red areas are lighter and therefore are closer to being in-focus. The image with index 5 contains almost no red. It mostly is coloured blue. The highlighted spots are consistent across images and also the predicted distances changes in accordance with the index. The last image (\autoref{fig:Results:Stack:HeatMap:Stiched}) shows the heatmap of the stitched image of the whole focus stack. The colouring is least apparent and the visible patterns match that of the other images.

\begin{figure}
    \centering
    \begin{subfigure}[b]{0.5\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/40_results/heatmap_legend.pdf}
    \end{subfigure}
    \begin{subfigure}[b]{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/40_results/heatmap_layer_3.pdf}
        \caption{stack index: 3}
        \label{fig:Results:Stack:HeatMap:Stack3}
        \vspace{1em}
    \end{subfigure}%
    \begin{subfigure}[b]{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/40_results/heatmap_layer_4.pdf}
        \caption{stack index: 4}
        \label{fig:Results:Stack:HeatMap:Stack4}
        \vspace{1em}
    \end{subfigure}
    \par
    \begin{subfigure}[b]{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/40_results/heatmap_layer_5.pdf}
        \caption{stack index 5}
        \label{fig:Results:Stack:HeatMap:Stack5}
    \end{subfigure}%
    \begin{subfigure}[b]{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/40_results/heatmap_stiched.pdf}
        \caption{stitched image}
        \label{fig:Results:Stack:HeatMap:Stiched}
    \end{subfigure}
    \caption{Figure comparing the heatmap of images of a focus stack to a generated image based on the focus prediction model (\acs{poop}-\acs{resnet}-34).}
    \label{fig:Results:Stack:HeatMap}
\end{figure}

Lastly, \autoref{fig:Results:Stack:ContourPlot} shows a contour plot of the image indexes that the model (\acs{poop}-\acs{resnet}-34) predicts to be most in focus. The majority of the image is predicted to be in focus with and index of 4. There are some patches with a predicted index of 5. A similar are is occupied by parts which are predicted to be in focus at index 3. Lastly, at the edges and in the corners some small areas are predicted to be best in focus in the image with index 2. 

\begin{figure}
    \centering
    \includegraphics[width=0.75\textwidth]{images/40_results/focus_stack_contour_plot.pdf}
    \caption{Contour plot showing which image of the focus stack is most in focus according to the model (\acs{poop}-\acs{resnet}-34).}
    \label{fig:Results:Stack:ContourPlot}
\end{figure}

\FloatBarrier

\section{Speed and Memory Consumption}
\label{sec:Results:Computation}

This section is detailing the hardware needed to run each model. Traditional methods need the least amount of memory and overall are the fastest. \Acl{nn} models, need the most additional memory and the memory and computation time increases with model size. 

\begin{itemize}
    \item speed measurements: \autoref{tab:Results:Computation:Speed} and \autoref{fig:Results:Computation:Speed}
    \item CNN similar performance to traditional metrics on CPU takes 2.5 longer as on GPU and for both abour double the time of MDCT
    \item Best model ResNet34 takes 17 times as long on GPU and 77 times as long on CPU compared to MDCT
    \item ResNet34 speedup compared to its own CPU version 11 times 
    \item ResNet34 runtime increases fairly linear when comparing to its size 
\end{itemize}


\begin{figure}
    \centering
    \includegraphics[width=0.75\textwidth]{images/40_results/speed.pdf}
    \caption{The mean speed of processing a patch by model on the \ac{cpu} and \ac{gpu}.}
    \label{fig:Results:Computation:Speed}
\end{figure}

\begin{table}[ht]
    \centering
    \caption{Comparison of model speed for processing a single patch in milliseconds on the \ac{cpu} and \ac{gpu}.}
    \label{tab:Results:Computation:Speed}
    \begin{tabular}{@{\extracolsep{6pt}}lrrrrrr@{}}
        \hline
        \multicolumn{1}{c}{} & \multicolumn{2}{c}{median} & \multicolumn{2}{c}{mean} & \multicolumn{2}{c}{std} \\
        \cline{2-3}\cline{4-5}\cline{6-7}
        name & \acs{gpu} & \acs{cpu} & \acs{gpu} & \acs{cpu} & \acs{gpu} & \acs{cpu} \\
        \hline
        \acs{mdct}                      & 0.20 &  0.49 & 0.23 &  0.50 & 0.06 & 0.08 \\
        \acs{vol4}                      & 0.11 &  0.13 & 0.11 &  0.13 & 0.01 & 0.01 \\
        \acs{laplacian}                 & 0.19 &  0.45 & 0.20 &  0.46 & 0.01 & 0.05 \\
        \hline
        \acs{poop}-\acs{fc}             & 0.32 &  6.75 & 0.33 &  6.78 & 0.04 & 0.28 \\
        \acs{poop}-\acs{cnn}            & 0.42 &  1.02 & 0.44 &  1.04 & 0.08 & 0.09 \\
        \acs{poop}-\acs{resnet}-101     & 9.35 & 82.75 & 9.46 & 84.28 & 0.88 & 8.83 \\
        \acs{poop}-\acs{resnet}-34      & 3.42 & 37.76 & 3.52 & 37.27 & 0.44 & 5.10 \\
        \acs{poop}-\acs{resnet}-18      & 1.95 & 19.66 & 1.99 & 19.67 & 0.22 & 2.67 \\
    \end{tabular}
\end{table}


\begin{itemize}
    \item model size (measured) \autoref{tab:Results:Computation:Memory}
    \item CNN by two orders of magnitude smaller than the second-largest model in terms of memory usage (ResNet-18)
\end{itemize}

\begin{table}[ht]
    \centering
    \caption{Additional memory usage by each model.}
    \label{tab:Results:Computation:Memory}
    \begin{tabular}{lr}
        \hline
        name & model size (MiB) \\
        \hline
        \acs{poop}-\acs{fc}         & 135.1 \\
        \acs{poop}-\acs{cnn}        &   0.4 \\
        \acs{poop}-\acs{resnet}-101 & 164.1 \\
        \acs{poop}-\acs{resnet}-34  &  81.4 \\
        \acs{poop}-\acs{resnet}-18  &  42.8 \\
    \end{tabular}
\end{table}

