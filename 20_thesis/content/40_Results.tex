\chapter{Results}
\label{ch:Results}

\todo[inline, caption={}]{
    \begin{itemize}
        \item Shows the findings of the project, often in the form of data.
        \item Comments on those findings which illustrate the significance of the results.
        \item Data Commentary:
        \begin{itemize}
            \item It is important to comment on the visual information, highlighting to your reader what they should notice and why this is important. 
            \item Location statement
            \item Linking as-statement
            \item Highlighting statement: drawing attention to key information.
        \end{itemize} 
    \end{itemize}
}

\section{Focus Distance Prediction}
\label{sec:Results:FocusDistance}

When the task is to estimate the distance or offset to the best focus value \acs{poop}-\acs{resnet}-34 performs best, followed by \acs{poop}-\acs{resnet}-101 and \acs{poop}-\acs{resnet}-18 (refer to \autoref{tab:Results:Models:Accuracy}). \Acs{poop}-\acs{resnet}-34 reaches a \ac{mae} of $0.0056$ which is an average error of less than one image in a focus stack (approximately $0.007$). Further the \ac{srcc} and \ac{plcc} are above $0.9$ thereby showing a strong correlation. The \ac{r2} score of $0.86$ supports this as well.
The worst performing model is \acs{poop}-\acs{fc} with most metrics lying below $0.04$ except \ac{srcc} with a value of $0.12$. This model shows no direct correlation with the focus input data. The \acs{poop}-\acs{cnn}'s \ac{mae} is only slightly worse than \acs{poop}-\acs{resnet} models. It shows still some good correlation for \ac{srcc} and \ac{plcc}, however the \ac{r2} score is just below $0.70$. 

\begin{table}
    \centering
    \caption{Comparing \acs{poop} models on the task of predicting the relative position of the focus plane.}
    \begin{tabular}{lrrrr}
        \hline
        method          & \acs{mae} & \acs{srcc} & \acs{plcc} & \acs{r2} \\
        \hline
        \acs{poop}-\acs{fc}             & 0.0170 & 0.1154 & 0.0357 & 0.0008 \\
        \acs{poop}-\acs{cnn}            & 0.0085 & 0.8605 & 0.8424 & 0.6911 \\
        \acs{poop}-\acs{resnet}-101     & 0.0064 & 0.9177 & 0.9057 & 0.8121 \\
        \acs{poop}-\acs{resnet}-34      & \underline{0.0056} & \underline{0.9386} & \underline{0.9261} & \underline{0.8570} \\
        \acs{poop}-\acs{resnet}-18      & 0.0075 & 0.9014 & 0.8847 & 0.7521 \\
    \end{tabular}
    \label{tab:Results:Models:Accuracy}
\end{table}

\autoref{fig:Results:ScatterPredictedTarget} shows the predictions of in comparison to the targeted values when using \acs{poop}-\acs{resnet}-34. The plot shows a line which represents the ideal match between targets and predictions. The data points in the plot clearly follow this line, they however have an approximate spread of 0.01 across most predictions. When a target range close to zero is reached the observed vertical spread is larger. Negative predictions also mostly correspond to negative targets. Further, one outlier can be seen with a target value of smaller than $-0.08$ and one with a target value of smaller than $-0.05$. Additional outliers are seen across the whole plot which increase the spread quite substantially.


\begin{figure}
    \centering
    \includegraphics[width=0.75\textwidth]{images/40_results/scatter_predictions_targets.pdf}
    \caption{The predictions plotted compared to targets with the ideal drawn as a line (using \acs{poop}-\acs{resnet}-34).}
    \label{fig:Results:ScatterPredictedTarget}
\end{figure}

\todo[inline]{should I add a second plot of prediction vs targets for cnn? \autoref{fig:Results:ScatterPredictedTarget}}

To give a clearer overview of the predictions also a histogram has been plotted. The histogram in \autoref{fig:Results:HistogramPredictedTarget} shows a fairly similar distribution between ground truth and targets. Of note, however, is that there are no predictions for bins starting at lower than $-0.04$. Further focus values slightly below zero are not predicted as often and focus values around $-0.03$ and around $0.02$ seem to be predicted disproportionally often especially compared to the ground truth. This is consistent with the higher spread observed close to zero in \autoref{fig:Results:ScatterPredictedTarget}.

\begin{figure}
    \centering
    \includegraphics[width=0.75\textwidth]{images/40_results/histogram_predictions_targets.pdf}
    \caption{A histogram showing the distribution of predicted focus compared to annotated focus (using \acs{poop}-\acs{resnet}-34).}
    \label{fig:Results:HistogramPredictedTarget}
\end{figure}

\todo[inline]{should I add a second histogram of prediction vs targets for cnn? \autoref{fig:Results:HistogramPredictedTarget}}


\section{Comparison to Traditional Focus Methods}
\label{sec:Results:TraditionalFocusMethods}

The models are also compared to traditional focus methods. The results of this comparison are shown in \autoref{tab:Results:Comparison:RelatedWorks:Accuracy} and \autoref{tab:Results:Comparison:RelatedWorks:IndexMAE}.

\autoref{tab:Results:Comparison:RelatedWorks:Accuracy} shows the accuracy of models when predicting the correct image ($\pm 1$) of a focus stack. A higher accuracy is a better. Of note is the high accuracy when using \ac{mdct}. In overall accuracy \ac{mdct} beats all other traditional methods with a large margin. Further it reaches a higher result than all neural network based models except the best performing \acs{poop}-\acs{resnet}-32. Also, of note should be that of \acs{poop}-\acs{cnn} which reaches an accuracy of $0.71$ and thereby beats most traditional methods (\ac{vol4} and \ac{laplacian}). The worst performing model is \acs{poop}-\acs{fc} followed by \ac{vol4}.

A similar result can be seen bin\autoref{tab:Results:Comparison:RelatedWorks:IndexMAE} which, shows \ac{mae}$^*$ of the index. With this metric a lower error shows a better result. The best performing model is \acs{poop}-\acs{resnet}-34 followed by \acs{mdct}. \Acs{mdct} has the lowest error when predicting hookworms, but all other categories are lead by \acs{poop}-\acs{resnet}-34. \Acs{poop}-\acs{resnet}-18 commonly is off by one image with an error of $0.95$. The same data as also visualized in \autoref{fig:Results:Comparison:RelatedWorks:IndexMAE} as a violin plot. The violin plot shows that maximum error for \ac{mdct} is fairly low. Errors of \ac{mdct} where the index is predicted in the negative direction do not exceed an off by minus one. The positive direction however is off to a larger extend. The overall maximum and minimum error of \acs{poop}-\acs{resnet}-34 are in a similar range, however, it is more symmetric. Another characteristic that the plot reveals is that the mean of most metrics is close to zero.


\begin{table}
    \centering
    \caption{Comparing \acs{poop} to other methods in terms of accuracy of finding the best in-focus image ($\pm 1$) from a focus stack.}
    \begin{tabular}{lrrrrr}
        \hline
        \multicolumn{1}{c}{} & \multicolumn{5}{c}{accuracy} \\
        \cline{2-6}
        method & all & trichuris & ascaris & schistosoma & hookworm \\
        \hline
        \acs{mdct}                      & \underline{0.84} & \underline{0.62} & \underline{0.87} & \underline{0.88} & \underline{1.00} \\
        \acs{vol4}                      & 0.31 & 0.38 & 0.47 & 0.31 & 0.07 \\
        \acs{laplacian}                 & 0.60 & 0.50 & 0.73 & 0.62 & 0.53 \\
        \hline
        \acs{poop}-\acs{fc}             & 0.21 & 0.25 & 0.27 & 0.12 & 0.20 \\
        \acs{poop}-\acs{cnn}            & 0.71 & 0.50 & 0.80 & 0.75 & 0.80 \\
        \acs{poop}-\acs{resnet}-101     & 0.82 & 0.69 & 0.80 & 0.88 & 0.93 \\
        \acs{poop}-\acs{resnet}-34      & \underline{0.90} & \underline{0.94} & \underline{0.87} & \underline{0.94} & 0.87 \\
        \acs{poop}-\acs{resnet}-18      & 0.82 & 0.69 & 0.73 & 0.88 & \underline{1.00} \\ 
    \end{tabular}
    \label{tab:Results:Comparison:RelatedWorks:Accuracy}
\end{table}

\begin{table}
    \centering
    \caption{Comparing \acs{poop} to other methods in terms of \ac{mae} of image indexes compared to the best in-focus image from a focus stack.}
    \begin{tabular}{lrrrrr}
        \hline
        \multicolumn{1}{c}{} & \multicolumn{5}{c}{\ac{mae}$^*$} \\
        \cline{2-6}
        method & all & trichuris & ascaris & schistosoma & hookworm \\
        \hline
        \acs{mdct}      & \underline{0.87} & \underline{1.56} & \underline{0.80} & \underline{0.69} & \underline{0.40} \\
        \acs{vol4}      & 2.45 & 1.88 & 2.07 & 2.50 & 3.40 \\
        \acs{laplacian} & 1.60 & 1.81 & 1.33 & 1.56 & 1.67 \\
        \hline
        \acs{poop}-\acs{fc}              & 3.53 & 3.00 & 3.20 & 4.06 & 3.87 \\
        \acs{poop}-\acs{cnn}             & 1.19 & 1.38 & 1.00 & 1.19 & 1.20 \\
        \acs{poop}-\acs{resnet}-101      & 0.92 & 1.06 & 1.07 & 0.94 & 0.60 \\
        \acs{poop}-\acs{resnet}-34       & \underline{0.65} & \underline{0.63} & \underline{0.80} & \underline{0.56} & 0.60 \\
        \acs{poop}-\acs{resnet}-18       & 0.95 & 1.31 & 0.87 & 1.06 & \underline{0.53} \\
    \end{tabular}
    \label{tab:Results:Comparison:RelatedWorks:IndexMAE}
\end{table}

\begin{figure}
    \centering
    \includegraphics[width=0.75\textwidth]{images/40_results/index_diff_to_gt_violin.pdf}
    \caption{Comparing \acs{poop} to other methods in terms of \ac{mae}$^*$ of image indexes compared to the best in-focus image from a focus stack. The same data is represented in \autoref{tab:Results:Comparison:RelatedWorks:IndexMAE}.}
    \label{fig:Results:Comparison:RelatedWorks:IndexMAE}
\end{figure}


\section{Heatmap and Stitched Image Generation}
\label{sec:Results:HeatStiched}

\begin{itemize}
    \item Model can be used for other things than predicting focus distance
    \item Heatmap shows distance from focus plane.
    \item Heatmap data can be used to generate contour plot that shows when which parts of an image are in focus.
    \item Stitch image together
\end{itemize}

\begin{figure}
    \centering
    \begin{subfigure}[b]{0.75\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/40_results/heatmap_legend.pdf}
    \end{subfigure}
    \begin{subfigure}[b]{0.5\textwidth}
        \centering
        \caption{stack index 3}
        \includegraphics[width=\textwidth]{images/40_results/heatmap_layer_3.pdf}
        \label{fig:Results:Stack:HeatMap:Stack3}
    \end{subfigure}%
    \begin{subfigure}[b]{0.5\textwidth}
        \centering
        \caption{stack index 4}
        \includegraphics[width=\textwidth]{images/40_results/heatmap_layer_4.pdf}
        \label{fig:Results:Stack:HeatMap:Stack4}
    \end{subfigure}
    \par
    \begin{subfigure}[b]{0.5\textwidth}
        \centering
        \caption{stack index 5}
        \includegraphics[width=\textwidth]{images/40_results/heatmap_layer_5.pdf}
        \label{fig:Results:Stack:HeatMap:Stack5}
    \end{subfigure}%
    \begin{subfigure}[b]{0.5\textwidth}
        \centering
        \caption{stitched image}
        \includegraphics[width=\textwidth]{images/40_results/heatmap_stiched.pdf}
        \label{fig:Results:Stack:HeatMap:Stiched}
    \end{subfigure}
    \caption{Figure comparing the heatmap of images of a focus stack to a generated image based on the focus prediction model (\acs{poop}-\acs{resnet}-34).}
    \label{fig:Results:Stack:HeatMap}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{images/40_results/focus_stack_contour_plot.pdf}
    \caption{Contour plot showing which image of the focus stack is most in focus according to the model (\acs{poop}-\acs{resnet}-34).}
    \label{fig:Results:Stack:ContourPlot}
\end{figure}

\begin{figure}
    \centering
    \begin{subfigure}[b]{\textwidth}
        \centering
        \caption{stack index: 4}
        \includegraphics[width=\textwidth]{images/40_results/focus_stack_4.jpg}
        \label{fig:Results:Stack:SideBySide:Index0}
    \end{subfigure}
    \begin{subfigure}[b]{\textwidth}
        \centering
        \caption{stack index: 5}
        \includegraphics[width=\textwidth]{images/40_results/focus_stack_5.jpg}
        \label{fig:Results:Stack:SideBySide:Index1}
    \end{subfigure}
    \begin{subfigure}[b]{\textwidth}
        \centering
        \caption{stack index: 6}
        \includegraphics[width=\textwidth]{images/40_results/focus_stack_6.jpg}
        \label{fig:Results:Stack:SideBySide:Index2}
    \end{subfigure}
    \begin{subfigure}[b]{\textwidth}
        \centering
        \caption{stitched image}
        \includegraphics[width=\textwidth]{images/40_results/focus_stack_stiched.png}
        \label{fig:Results:Stack:SideBySide:Stiched}
    \end{subfigure}
    \caption{Comparison of images from the focus stack to a generated combined image based on the focus prediction of the model (\acs{poop}-\acs{resnet}-34).}
    \label{fig:Results:Stack:SideBySide}
\end{figure}

\section{Speed and Memory Consumption}
\label{sec:Results:Computation}

This section is detailing the hardware needed to run each model. Traditional methods need the least amount of memory and overall are the fastest. \Acl{nn} models, need the most additional memory and the memory and computation time increases with model size. 

\begin{itemize}
    \item speed measurements: \autoref{tab:Results:Computation:Speed} and \autoref{fig:Results:Computation:Speed}
    \item CNN similar performance to traditional metrics on CPU takes 2.5 longer as on GPU and for both abour double the time of MDCT
    \item Best model ResNet34 takes 17 times as long on GPU and 77 times as long on CPU compared to MDCT
    \item ResNet34 speedup compared to its own CPU version 11 times 
    \item ResNet34 runtime increases fairly linear when comparing to its size 
\end{itemize}


\begin{figure}
    \centering
    \includegraphics[width=0.75\textwidth]{images/40_results/speed.pdf}
    \caption{The mean speed of processing a patch by model on the \ac{cpu} and \ac{gpu}.}
    \label{fig:Results:Computation:Speed}
\end{figure}

\begin{table}[ht]
    \centering
    \caption{Comparison of model speed for processing a single patch in milliseconds on the \ac{cpu} and \ac{gpu}.}
    \label{tab:Results:Computation:Speed}
    \begin{tabular}{@{\extracolsep{6pt}}lrrrrrr@{}}
        \hline
        \multicolumn{1}{c}{} & \multicolumn{2}{c}{median} & \multicolumn{2}{c}{mean} & \multicolumn{2}{c}{std} \\
        \cline{2-3}\cline{4-5}\cline{6-7}
        name & \acs{gpu} & \acs{cpu} & \acs{gpu} & \acs{cpu} & \acs{gpu} & \acs{cpu} \\
        \hline
        \acs{mdct}                      & 0.20 &  0.49 & 0.23 &  0.50 & 0.06 & 0.08 \\
        \acs{vol4}                      & 0.11 &  0.13 & 0.11 &  0.13 & 0.01 & 0.01 \\
        \acs{laplacian}                 & 0.19 &  0.45 & 0.20 &  0.46 & 0.01 & 0.05 \\
        \hline
        \acs{poop}-\acs{fc}             & 0.32 &  6.75 & 0.33 &  6.78 & 0.04 & 0.28 \\
        \acs{poop}-\acs{cnn}            & 0.42 &  1.02 & 0.44 &  1.04 & 0.08 & 0.09 \\
        \acs{poop}-\acs{resnet}-101     & 9.35 & 82.75 & 9.46 & 84.28 & 0.88 & 8.83 \\
        \acs{poop}-\acs{resnet}-34      & 3.42 & 37.76 & 3.52 & 37.27 & 0.44 & 5.10 \\
        \acs{poop}-\acs{resnet}-18      & 1.95 & 19.66 & 1.99 & 19.67 & 0.22 & 2.67 \\
    \end{tabular}
\end{table}


\begin{itemize}
    \item model size (measured) \autoref{tab:Results:Computation:Memory}
    \item CNN by two orders of magnitude smaller than the second-largest model in terms of memory usage (ResNet-18)
\end{itemize}

\begin{table}[ht]
    \centering
    \caption{Additional memory usage by each model.}
    \label{tab:Results:Computation:Memory}
    \begin{tabular}{lr}
        \hline
        name & model size (MiB) \\
        \hline
        \acs{poop}-\acs{fc}         & 135.1 \\
        \acs{poop}-\acs{cnn}        &   0.4 \\
        \acs{poop}-\acs{resnet}-101 & 164.1 \\
        \acs{poop}-\acs{resnet}-34  &  81.4 \\
        \acs{poop}-\acs{resnet}-18  &  42.8 \\
    \end{tabular}
\end{table}



\todo[inline]{
    CPU:
    microscopes: Jetson Nano: ARM Cortex-A57 4 Core 1479 MHz (cpubenchmark: 400 (single-thread), 947 (multi))
    egghead: Ryzen 5 2600X: 2406 (single), 14050 (multicore) 
    rasberry pi 4: 569 (single), 853 (multi)

    \url{https://www.cpubenchmark.net/compare/ARM-Cortex-A57-4-Core-1479-MHz-vs-AMD-Ryzen-5-2600X-vs-ARM-Cortex-A72-4-Core-1800-MHz/3914vs3235vs4078}

    GPU:
    microscopes: Jetson Nano: 236 GFLOPS (FP32)
    egghead: RTX 2070: 7465 GFLOPS (FP32) 
    rasberry pi 4: -

    \url{https://www.techpowerup.com/gpu-specs/jetson-nano-gpu.c3643}
    \url{https://www.techpowerup.com/gpu-specs/geforce-rtx-2070.c3252}

    Add estimated performance for different hardware/model combinationshttps://www.techpowerup.com/gpu-specs/jetson-nano-gpu.c3643
}
