\chapter{Foundations}
\label{ch:Foundations}

This chapter introduces relevant background information about \aclp{ntd}, which method, namely Kato-Katz \textcite{katz1972simple}, is used to detect eggs for diagnosis. Further, it elaborates on microscopy related topics like \ac{wsi}. Moreover, \acp{nn} are introduced. It is shown how they, work, further developments and architecture is presented. Lastly, related literature is introduced.

\section{Neglected Tropical Diseases}
\label{sec:Foundations:NTDs}

\Acp{ntd} \cite{feasey2010neglected} are a biologically diverse group of diseases which mainly occur in tropical regions. The geographic location, however, is not linked to temperatures or climate but mainly as a result of a large part of the world's poorest population living in these regions. \Acp{ntd} affect approximately a sixth of the world population, yet, they have received less attention than other diseases. \textcite{feasey2010neglected} state that there are \acp{ntd} which have a high prevalence and excellent potential for successful control. Among these are Ascaris, hookworm, whipworm, and Schistosoma. These parasites are the ones present in the dataset used in this thesis. Ascaris, whipworm and hookworm are \acp{sth} which is a subclass of \acp{ntd}\todo{Source for subclass}.

\subsection{Soil-Transmitted Helminth} % Soil-Transmitted Helminths
\label{sec:Foundations:NTDs:STHs} 

Helminthic parasites which are mainly transmitted through soil are known as \aclp{sth} \cite{feasey2010neglected,jourdan2018soiltransmitted}. This section gives a more detailed introduction into \acp{sth} present in the dataset used in this thesis.


\subsubsection{Roundworm (Ascaris)}
\label{sec:Foundations:NTDs:STHs:Ascaris}

The roundworm (Ascaris) is the most common among \acp{sth} \cite{jamison2006helminth}. Upon oral ingestion ascaris eggs hatch and larvae move through the lungs to settle into the small intestine where they grow into adult worms \cite{jourdan2018soiltransmitted}. There they reproduce sexually and produce eggs which are expelled through human faeces. Eggs in warm, moist soil can infect other humans for years. An illustration of a roundworm can be seen in \autoref{fig:Foundations:NCLs:STHs:Ascaris}.

\subsubsection{Whipworm (Trichuris)}
\label{sec:Foundations:NTDs:STHs:Whipworm}

Like roundworms whipworms are also transmitted through the faecal-oral cycle, where eggs are ingested via food or hands \cite{jourdan2018soiltransmitted}. Whipworms also reproduce in the small intestine, however, unlike roundworms, they do not migrate through the lungs. \autoref{fig:Foundations:NCLs:STHs:Whipworm:Adult} shows an illustration of a whipworm.

\subsubsection{Hookworm (Necator Americanus and Ancylostoma Duodenale)}
\label{sec:Foundations:NTDs:STHs:Hookworm}

Unlike roundworms and whipworms, hookworms' eggs hatch after around 5-10 days outside the human body. Roundworm larva then infect humans by penetrating the skin through the feet \cite{jourdan2018soiltransmitted}. They then travel through the lungs into the voice box (larynx) where they are swallowed. Finally, hookworms, like roundworms and whipworms settle in the small intestine and produce eggs which leave the human body through faeces. An image of a hookworm larva can be seen in \autoref{fig:Foundations:NCLs:STHs:Hookworm:Adult}.

\begin{figure}
    \begin{subfigure}[t]{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/20_foundations/10_neglected_tropical/Ascaris_adult_enlarged.jpg}
        \caption{Illustration of a \textbf{roundworm} by \textcite{blainville1824traite}.}
        \label{fig:Foundations:NCLs:STHs:Ascaris}
        \vspace*{2mm}
    \end{subfigure}
    \hfill
    \begin{subfigure}[t]{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/20_foundations/10_neglected_tropical/Trichuris_trichiura_adult_female_enlarged.jpg}
        \caption{An illustration of a female \textbf{whipworm} by \textcite{blainville1824traite}.}
        \label{fig:Foundations:NCLs:STHs:Whipworm:Adult}
        \vspace*{2mm}
    \end{subfigure}
    \begin{subfigure}[t]{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/20_foundations/10_neglected_tropical/Hookworm_larva.jpg}
        \caption{\textbf{Hookworm} larva (from \textcite{dpdx2019hookworm}).}
        \label{fig:Foundations:NCLs:STHs:Hookworm:Adult}
    \end{subfigure}    
    \hfill
    \begin{subfigure}[t]{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/20_foundations/10_neglected_tropical/Schistosoma_adult_small.jpg}
        \caption{Electron micrograph of a male \textbf{Schistosoma} by \textcite{davidwilliams2009schistosoma}.}
        \label{fig:Foundations:NCLs:Schistosoma:Adult}
    \end{subfigure}
    \caption{An overview of parasitic worms. Roundworm, whipworm, hookworm, and Schistosoma (left to right, top to bottom).}
    \label{fig:Foundations:NCLs:Overview}
\end{figure}


\subsection{Schistosoma}
\label{sec:Foundations:NTDs:STHs:Schistosoma}

Schistosoma worms have the most complex life cycle among parasite covered in this thesis. Humans excrement contains its eggs \cite{nelwan2019schistosomiasis}. When eggs come into contact with water they hatch and infect snails. Infected snails shed cercariae which enter the human body through skin and migrate throughout the body using the circulating blood. The location where adult worms settle depends on the exact species, but some examples are the intestine (large and small), and the bladder. A picture of a Schistosoma worm can be seen in \autoref{fig:Foundations:NCLs:Schistosoma:Adult}.

\subsection{Diagnosis}
\label{sec:Foundations:NTDs:Diagnosis}

Schistosoma and \acp{sth} are commonly diagnosed by counting eggs present in a stool sample with a microscope. The technique used is called Kato-Katz \cite{nelwan2019schistosomiasis} and was introduced by \textcite{katz1972simple} which refined the method introduced by \citeauthor{kato1954comparative} \cite{kato1954comparative,kato1960correct}. The technique involves cardboard with a hole in it, some stainless-steel mesh-cloth, a cellophane membrane and glycerol. A sample first is pressed through the stainless steel mesh-cloth and then smeared through the hole onto the slide. Then the side is covered with a cellophane membrane and treated with glycerol \cite{mbongngwese2020diagnostic}. This technique gains fairly consistent measurements, is fairly reliable, easy to perform and low cost \cite{katz1972simple} and therefore considered to be the \ac{who} \say{gold standard} (according to \textcite{mbongngwese2020diagnostic}).
The slides prepared using the Kato-Katz method are, after a resting period, examined under a light microscope to count the number of eggs per milligram. This allows to identify the intensity of infection of a patient \cite{feasey2010neglected}. 

Eggs found under a microscope can be assigned to the corresponding parasite worm based on size, shape, and colour. \emph{Roundworm (Ascaris)} eggs are identified by rounded thick shell with an external mamillated layer which is often stained with brown spots and has a length of \unit{45}{\micro\meter} to \unit{75}{\micro\meter} \cite{dpdx2019ascariasis} (as shown in \autoref{fig:Foundations:NCLs:Diagnosis:Ascaris:Egg}).
\emph{Whipworm} eggs (see \autoref{fig:Foundations:NCLs:Diagnosis:Whipworm:Egg}) can be identified by their elongated oval shape with two circular protrusions at the end of longer sides \cite{dpdx2017trichuriasis,larsson2020development}. A length of approximately \unit{50}{\micro\meter} and a width of \unit{20}{\micro\meter} characterizes the eggs.
\emph{Hookworm} eggs are thin-shelled and colourless with a blurry inner structure. The eggs' size measures \unit{65}{\micro\meter} by \unit{35}{\micro\meter} which is shown in \autoref{fig:Foundations:NCLs:Diagnosis:Hookworm:Egg} \cite{dpdx2019hookworm, larsson2020development}.
Lastly, the dataset contains \emph{Schistosoma} eggs (see \autoref{fig:Foundations:NCLs:Diagnosis:Schistosoma:Egg}). They are characterized by a spine (seen as a spike) 
and have a size of approximately \unit{100}{\micro\meter} by \unit{50}{\micro\meter} which can vary by species \cite{dpdx2019schistosomiasis, larsson2020development}.

\begin{figure}[tb]
    \centering
    \begin{subfigure}[t]{0.4\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/20_foundations/10_neglected_tropical/Ascaris_egg_fertilised.jpg}
        \caption{Fertilized \textbf{roundworm} egg \cite{dpdx2019ascariasis}.}
        \label{fig:Foundations:NCLs:Diagnosis:Ascaris:Egg}
        \vspace*{2mm}
    \end{subfigure}
    \hspace*{1em}
    \begin{subfigure}[t]{0.4\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/20_foundations/10_neglected_tropical/Trichuris_trichiura_egg.jpg}
        \caption{\textbf{Whipworm} egg \cite{dpdx2017trichuriasis}.}
        \label{fig:Foundations:NCLs:Diagnosis:Whipworm:Egg}
        \vspace*{2mm}
    \end{subfigure}

    \begin{subfigure}[t]{0.4\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/20_foundations/10_neglected_tropical/Hookworm_egg.jpg}
        \caption{\textbf{Hookworm} egg \cite{dpdx2019hookworm}.}
        \label{fig:Foundations:NCLs:Diagnosis:Hookworm:Egg}
    \end{subfigure}
    \hspace*{1em}
    \begin{subfigure}[t]{0.4\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/20_foundations/10_neglected_tropical/Schistosoma_egg.jpg}
        \caption{\textbf{Schistosoma} mansoni egg \cite{dpdx2019schistosomiasis}.}
        \label{fig:Foundations:NCLs:Diagnosis:Schistosoma:Egg}
    \end{subfigure}
    \caption{An overview of parasitic worm eggs.}
    \label{fig:Foundations:NCLs:Diagnosis:Overview}
\end{figure}

\subsection{Whole-Slide Imaging}
\label{sec:Foundations:NTDs:WHoleSlideImaging}

\Ac{wsi} \cite{ghaznavi2013digital, hanna2019whole, el-gabry2014wholeslide} is a process in which slides are wholistically scanned to create a digital copy. This allows diagnostic processes to be more flexible as the collection of slides is independent of its analysis. Further, digitally archived slides do not suffer any degradation. 

A commonly used focus method for \ac{wsi} is \emph{z-stacking} \cite{el-gabry2014wholeslide} which is required for slides with larger variation in topology or which have a three-dimensional structure e.g., thick smears. A z-stack consists of multiple images taken at different focus planes. This allows a researcher to emulate the focusing behaviour of a conventional light microscope. \todo{Should example of a focus stack be added?}

\section{Artificial Neural Networks}
\label{sec:Foundations:NeuralNetworks}

\todo[inline]{General quick introduction to neural networks.}

\subsection{Feedforward Neural Networks}
\label{sec:Foundations:NeuralNetworks:FNN}

According to \textcite{nielsen2015neural} artificial neural networks were developed by \textcite{rosenblatt1958perceptron}. In feedforward neural networks information flows only from input towards the output. There is no backwards flow of information, hence, the name.
A \ac{nn} is consists of multiple layers which themselves consists of individual neurons.

\subsubsection{Perceptrons and Neurons}
\label{sec:Foundations:NeuralNetworks:Perceptrons}

A perceptron (see \autoref{fig:Foundations:ANNs:Perceptron}) is a type of artificial neuron that consists of inputs ($x_1, \cdots, x_n$), weights ($w_1, \cdots, w_n$) that correspond to each input, a threshold/bias $b$ and an output \cite{nielsen2015neural}.


\tikzset{basic/.style={draw,fill=white,
                       text badly centered,minimum width=2em}}
\tikzset{input/.style={basic,circle}}
\tikzset{weights/.style={basic,rectangle,minimum width=2em}}
\tikzset{functions/.style={basic,circle,fill=white}}
\newcommand{\addsymbol}{\draw[thick] (0.5em,0.5em) -- (0,0.5em) -- 
                        (0,-0.5em) --  (-0.5em,-0.5em)
                        (0em,0.75em) -- (0em,-0.75em)
                        (0.75em,0em) -- (-0.75em,0em);}
\begin{figure}
    \centering
    % https://tex.stackexchange.com/a/104376
    \begin{tikzpicture}
        \node[functions] (center) {};
        \draw[thick] (0.5em,0.5em) -- (0,0.5em) -- (0,-0.5em) -- (-0.5em,-0.5em);
        \draw (0em,0.75em) -- (0em,-0.75em);
        \draw (0.75em,0em) -- (-0.75em,0em);
        \node[right of=center] (right) {};
            \path[draw,->] (center) -- (right);
        \node[functions,left=3em of center] (left) {$\sum$};
            \path[draw,->] (left) -- (center);
        \node[weights,left=3em of left] (2) {$w_2$} -- (2) node[input,left of=2] (l2) {$x_2$};
            \path[draw,->] (l2) -- (2);
            \path[draw,->] (2) -- (left);
        \node[below of=2] (dots) {$\vdots$} -- (dots) node[left of=dots] (ldots) {$\vdots$};
        \node[weights,below of=dots] (n) {$w_n$} -- (n) node[input,left of=n] (ln) {$x_n$};
            \path[draw,->] (ln) -- (n);
            \path[draw,->] (n) -- (left);
        \node[weights,above of=2] (1) {$w_1$} -- (1) node[input,left of=1] (l1) {$x_1$};
            \path[draw,->] (l1) -- (1);
            \path[draw,->] (1) -- (left);
        \node[weights,below of=left] (0) {$b$};
            \path[draw,->] (0) -- (left);
    \end{tikzpicture}
    \caption{Visualization of a perceptron.}
    \label{fig:Foundations:ANNs:Perceptron}
\end{figure}

A perceptron computes its output by multiplying each input with its corresponding weight. The result of these multiplications in then summed and compared to a threshold value. \autoref{eq:Perceptron} shows this computation.

\begin{equation}
    output = 
    \begin{cases}\label{eq:Perceptron}
    0 & if:\; \sum_{1}^{n}(w_i \cdot x_i) + b \le 0 \\
    1 & if:\; \sum_{1}^{n}(w_i \cdot x_i) + b > 0
    \end{cases}
\end{equation}

The equation can be simplified by denoting ($x_1, \cdots, x_n$) and ($w_1, \cdots, w_n$) as vectors $x$ and $y$:

\begin{equation}
    output = 
    \begin{cases}\label{eq:PerceptronVector}
    0 & if:\; \vec{w} \cdot \vec{x} + b \le 0 \\
    1 & if:\; \vec{w} \cdot \vec{x} + b > 0
    \end{cases}
\end{equation}

Today, \acp{nn} do not use classical perceptrons. Instead of applying a threshold function to $\vec{w} \cdot \vec{x} + b$ the neurons apply a non-linear activation function. This gives neural networks the capability to approximate non-linear functions \cite{cybenko1989approximation, hornik1991approximation, sharma2020activation}.

\subsubsection{Activation Function}
\label{sec:Foundations:NeuralNetworks:ActivationFunction}
\todo{Sigmoid function.}

A widely used activation function is \ac{relu} \todo{cite relu paper}. It is defined by setting all negative values to zero. Otherwise, the value of the function stays the same. Therefore, \ac{relu} can be expressed as $f(x)  = max(x,0)$. The cut-off below zero makes this function non-linear, thereby giving a neural network more expressive power. Moreover, cutting off negative values means that the number of active neurons at the same time is reduced which makes \ac{relu} more efficient \cite{sharma2020activation}.

Another function that is commonly used is Softmax. It is used in the last layers of classification to normalize output values. The exponential function is applied to each value. The resulting values are normalized by dividing them through the sum of all values. This results in the following equation.

\todo[inline]{write section}

\todo[inline, caption={}]{
    \begin{itemize}
        \item ReLU (for \cite{senaras2018deepfocus})
        \item SoftMax (for \cite{senaras2018deepfocus})
    \end{itemize}
}


\subsubsection{Layer}
\label{sec:Foundations:NeuralNetworks:Layer}

Neurons and their corresponding activation functions are combined into layers. The first layer is called the input layer and the last layer the output layer \cite{nielsen2015neural}. Layers in between are referred to as hidden layers. In fully connected neural networks \todo{source} each neuron of each layer is connected to each neuron of the previous layer. Layers that have this property are commonly called fully connected layers \todo{source}. 

Commonly, fully connected neural networks are shown as a graph (see \autoref{fig:Foundations:ANNs:Layer:FullyConnected}), however, mathematically, each layer is represented as a matrix of weights $\mat{W}$ and a vector of biasses $\vec{b}$. Each row vector $\vec{w_i}$ of the matrix corresponds to one neuron and the scalar $b_i$ constitutes the bias for neuron $i$. When processing input $\vec{x}$ the weight matrix is multiplied with the input vector, the bias vector $\vec{b}$ is then added, and, lastly, an activation function $f$ is applied (see \autoref{eq:FCNNLayer}).

\begin{equation}
    \label{eq:FCNNLayer}
    output = f(\mat{W} \cdot \vec{x} + \vec{b}) = f( \begin{pmatrix}
        \vec{w_1} \cdot \vec{x} + b_1\\
        \vdots \\
        \vec{w_n} \cdot \vec{x} + b_n
      \end{pmatrix} )
\end{equation}

% Adapted from https://tex.stackexchange.com/a/618305
\tikzset{>=latex} % for LaTeX arrow head
\tikzstyle{node}=[basic,circle,minimum size=22,inner sep=0.5,outer sep=0.6]
\tikzstyle{connect}=[->,basic,black,shorten >=1]
\tikzset{ % node styles, numbered for easy mapping with \nstyle
  node 1/.style={node,black,draw=black,fill=white},
  node 2/.style={node,black,draw=black,fill=white},
  node 3/.style={node,black,draw=black,fill=white},
}
\def\nstyle{int(\lay<\Nnodlen?min(2,\lay):3)} % map layer number onto 1, 2, or 3

\begin{figure}
    \centering
    % NEURAL NETWORK
    \begin{tikzpicture}[x=2.4cm,y=1.2cm]
        \readlist\Nnod{4,3,3,2} % array of number of nodes per layer
        \readlist\Nstr{n,m,k} % array of string number of nodes per layer
        \readlist\Cstr{x,h^{(\prev)},y} % array of coefficient symbol per layer
        \def\yshift{0.55} % shift last node for dots
        
        % LOOP over LAYERS
        \foreachitem \N \in \Nnod{
        \def\lay{\Ncnt} % alias of index of current layer
        \pgfmathsetmacro\prev{int(\Ncnt-1)} % number of previous layer
        \foreach \i [evaluate={\c=int(\i==\N); \y=\N/2-\i-\c*\yshift;
                    \x=\lay; \n=\nstyle;
                    \index=(\i<\N?int(\i):"\Nstr[\n]");}] in {1,...,\N}{ % loop over nodes
            % NODES
            \node[node \n] (N\lay-\i) at (\x,\y) {$\strut\Cstr[\n]_{\index}$};
            
            % CONNECTIONS
            \ifnumcomp{\lay}{>}{1}{ % connect to previous layer
            \foreach \j in {1,...,\Nnod[\prev]}{ % loop over nodes in previous layer
                \draw[white,line width=1.2,shorten >=1] (N\prev-\j) -- (N\lay-\i);
                \draw[connect] (N\prev-\j) -- (N\lay-\i);
            }
            \ifnum \lay=\Nnodlen
                \draw[connect] (N\lay-\i) --++ (0.5,0); % arrows out
            \fi
            }{
            \draw[connect] (0.5,\y) -- (N\lay-\i); % arrows in
            }
            
        }
        \path (N\lay-\N) --++ (0,1+\yshift) node[midway] {$\vdots$}; % dots
        }      
    \end{tikzpicture}
    \caption{Visualization of simple neural network with two hidden layers with $m$, an input layer with $n$ and an output layer with $k$ neurons.}
    \label{fig:Foundations:ANNs:Layer:FullyConnected}
\end{figure}

\subsubsection{Training Neural Networks}
\label{sec:Foundations:NeuralNetworks:Training}

\paragraph{Loss Function}
\label{par:Foundations:NeuralNetworks:Training:Loss}


\paragraph{Optimizer}
\label{par:Foundations:NeuralNetworks:Training:Optimizer}

\todo[inline, caption={}]{
    \begin{itemize}
        \item SDG (for \cite{senaras2018deepfocus})
        \item ADAM (for \cite{wang2020focuslitenn})
    \end{itemize}
}


\subsection{Convolutional Neural Networks}
\label{sec:Foundations:NeuralNetworks:CNN}

\Acp{cnn} are feedforward neural networks, however, instead of only using fully connected layers, \ac{cnn} use filters or convolutions \cite{teuwen2020convolutional}. Convolutions and filters consist of a filter matrix which can be understood as a sliding window. The values of the convolution matrix are multiplied with their corresponding pixel values and summed (see \autoref{fig:Foundations:ANNs:CNNs:Convolution}). Convolutions stem from traditional image processing \cite{shih2010image} and are used because they take the spacial structure of images directly into account \cite{nielsen2015neural}. Instead of having predefined filter matrices convolutional neural networks learn their values during training.

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{images/20_foundations/30_neural_networks/convolution.eps}
    \caption{An example of a convolutional (Laplace) filter.}
    \label{fig:Foundations:ANNs:CNNs:Convolution}
\end{figure}


\subsection{Architecture}
\label{sec:Foundations:NeuralNetworks:Architecture}

Large neural networks use similar patterns and, therefore, architectural building blocks exist. The building blocks relevant to this thesis are introduced in this section.
Of note is also, that architecture descriptions often describe activation functions as separate layers as can be seen in \todo{ref architecture}.

A layer type that can be commonly found in neural networks is the fully connected layer. In this layer each input is connected to each neuron. This is the layer-type used in fully connected \ac{nn} as introduced in \autoref{sec:Foundations:NeuralNetworks:FNN}.

Also, convolutional layers, were already introduced in \autoref{sec:Foundations:NeuralNetworks:CNN}. These layers use convolutions and, therefore, each neuron is only connected to its neighbours. What is considered to be its neighbours depends on the size of the convolution window.
\todo{introduce stride, kernelSize and outputDimensions \cite{liu2016computer}}

Closely related to convolutional layers are pooling layers. Pooling layers, however, unlike convolutions do not perform a sum operation on the inputs. Instead, they apply a pooling function (often, maximum or mean). Also, commonly with pooling layers the sliding window does not overlap ($stride = \frac{size(kernel)}{2}$), therefore, pooling can be understood as splitting the input into tiles and a pooling operation is done on each of those tiles. \todo{explain function of pooling layers}


\todo[inline]{Only explain used architectures}

\begin{itemize}
    \item Building Blocks (how do they work, what they are used for, parameters etc.)
    \begin{itemize}
        \item Fully connected
        \item Convolutional Layers (make sure to not repeat \autoref{sec:Foundations:NeuralNetworks:CNN})
        \item Dropout
        \item Batch normalization
    \end{itemize}
    \item ResNet \cite{he2016deep}
    \item ResNet-Wide \cite{zagoruyko2016wide}
    \item Inception
\end{itemize}

\section{Related Works}
\label{sec:Foundations:RelatedWorks}

\todo{introducting words about this section}

\subsection{Traditional Methods}
\label{sec:Foundations:RelatedWorks:Traditional}


\textcite{mateos-perez2012comparative} perform a comparative study on 13 real-time focus methods with fluorescence-labeled tuberculosis bacteria. They take into account, robustness to noise, illumination changes, accuracy and computational cost. Further, the study looks into the benefit of preprocessing with morphological operators.
The authors recommend the usage of \ac{mdct} (studied by \textcite{lee2008enhanced}) or \ac{vol4} \cite{vollath1988influence} due to their high accuracy, robustness to noise and low computational cost.

\todo{Go more into detail about vol4 and mdct, possibly put into separate section. Also add \ac{laplacian}}

\subsection{Deep Learning-Based Approaches}
\label{sec:Foundations:RelatedWorks:DeepLearning}

Related literature for out of focus detection that uses deep learning mostly uses pathology slides. Further, magnification levels of microscopes range from 20x to 40x, with the latter being most common. Moreover, commonly, the problem is phrased as a classification problem of either, \ac{oof} classes or simple binary classes.

\emph{DeepFocus} is a model developed in \textcite{senaras2018deepfocus} to classify an image tile as either in- or out-of-focus. It is the first deep learning model for focus-detection for the use in digital pathology. The training data used is generated by annotating the focus plane of focus stacks. Images that are annotated as in-focus and adjacent images in the stack are considered to be in focus. The model is a \ac{cnn} with five convolutional layers, three max pooling and two fully connected layers. The resulting classification model is compared to out-of-focus detection by \textcite{moleslopez2013automated} which use a more traditional machine learning approach with decision trees.
Additionally, the authors compare the computational performance of their approach with \textcite{moleslopez2013automated}. \emph{DeepFocus} performs slightly faster than \textcite{moleslopez2013automated} and offers a higher resolution. This approach allows GPU computations which can be used to further speed-up out of focus-detections.
The authors conclude that their approach provides good, spacial resolution and accuracy for identifying \ac{oof} regions in pathology slides. Moreover, they state that the use of GPUs allows faster processing times on ordinary hardware.

\textcite{kohlberger2019wholeslide} develop \emph{ConvFocus}, a truncated Inception (v3) model that classifies pathology slides based on how strongly out of focus they are. For this approach 30 different classes are used of which one class is considered to be in focus. The aim of this study is to use in-focus images and artificially generate out of focus training data.
The authors find that exclusively using Bokeh or Gaussian-blur for synthetic \ac{oof} images yields mediocre detection results. They indicate that artificial blurring is removing artefacts caused by edges of scan lanes and JPEG compression. Therefore, the authors re-add these types of artefacts after synthetic image blurring. They, introduced additional pixel noise to simulate the noise of image sensor.
The main findings of the authors show that their developed method can be used to generate additional data for training focus classifiers. Additionally, the authors show the effect of synthetic blur on detection accuracy of breast cancer prediction models and find that \ac{oof} images degrade performance.

An approach with a slightly different goal is followed by \textcite{wang2020focuslitenn} to develop \emph{FocusLite}. \emph{FocusLite} detect the degree to which images are out of focus but does not discern any directional information. The authors' goal is to develop a model which maintains similar speeds to knowledge-driven approaches, yet, surpasses their precision. The models are trained on \emph{FocusPath} \cite{hosseini2019encoding} and evaluated using a newly created dataset \emph{TCGA@Focus} and \emph{FocusPath} itself.
The authors conclude that their model surpasses all existing methods when considering the trade-off between precision and speed.  
