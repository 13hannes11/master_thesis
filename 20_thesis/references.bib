
@online{2021pytorch,
  title = {{{PyTorch}} Documentation — {{PyTorch}} 1.10 Documentation},
  date = {2021-10},
  url = {https://pytorch.org/docs/1.10/},
  urldate = {2022-03-28},
  keywords = {Libraries},
  file = {/var/home/hannes/Zotero/storage/JUGIE2MD/1.10.html}
}

@article{barenbold2017estimating,
  title = {Estimating Sensitivity of the {{Kato-Katz}} Technique for the Diagnosis of {{Schistosoma}} Mansoni and Hookworm in Relation to Infection Intensity},
  author = {Bärenbold, Oliver and Raso, Giovanna and Coulibaly, Jean T. and N’Goran, Eliézer K. and Utzinger, Jürg and Vounatsou, Penelope},
  editor = {French, Michael},
  date = {2017-10-04},
  journaltitle = {PLOS Neglected Tropical Diseases},
  shortjournal = {PLoS Negl Trop Dis},
  volume = {11},
  number = {10},
  pages = {e0005953},
  issn = {1935-2735},
  doi = {10.1371/journal.pntd.0005953},
  abstract = {The Kato-Katz technique is the most widely used diagnostic method in epidemiologic surveys and drug efficacy trials pertaining to intestinal schistosomiasis and soil-transmitted helminthiasis. However, the sensitivity of the technique is low, particularly for the detection of light-intensity helminth infections. Examination of multiple stool samples reduces the diagnostic error; yet, most studies rely on a single Kato-Katz thick smear, thus underestimating infection prevalence. We present a model which estimates the sensitivity of the Kato-Katz technique in Schistosoma mansoni and hookworm, as a function of infection intensity for repeated stool sampling and provide estimates of the age-dependent ‘true’ prevalence. We find that the sensitivity for S. mansoni diagnosis is dominated by missed light infections, which have a low probability to be diagnosed correctly even through repeated sampling. The overall sensitivity strongly depends on the mean infection intensity. In particular at an intensity of 100 eggs per gram of stool (EPG), we estimate a sensitivity of 50\% and 80\% for one and two samples, respectively. At an infection intensity of 300 EPG, we estimate a sensitivity of 62\% for one sample and 90\% for two samples. The sensitivity for hookworm diagnosis is dominated by day-to-day variation with typical values for one, two, three, and four samples equal to 50\%, 75\%, 85\%, and 95\%, respectively, while it is only weakly dependent on the mean infection intensity in the population. We recommend taking at least two samples and estimate the ‘true’ prevalence of S. mansoni considering the dependence of the sensitivity on the mean infection intensity and the ‘true’ hookworm prevalence by taking into account the sensitivity given in the current study.},
  langid = {english},
  file = {/var/home/hannes/Zotero/storage/SMKVUTDZ/Bärenbold et al. - 2017 - Estimating sensitivity of the Kato-Katz technique .pdf}
}

@book{blainville1824traite,
  title = {Traité zoologique et physiologique sur des vers intestinaux de l'homme},
  author = {de Blainville, H.-M. Ducrotay and Bremser, Johann Gottfried},
  date = {1824},
  publisher = {{C.L.F. Panckoucke}},
  location = {{Paris}},
  langid = {french},
  pagetotal = {vi, viii, iii, 574},
  keywords = {Helminths,Parasitology},
  annotation = {Open Library ID: OL33076995M},
  file = {/var/home/hannes/Zotero/storage/W2WKPVF6/Blainville and Bremser - 1824 - Traité zoologique et physiologique sur des vers in.pdf}
}

@article{cybenko1989approximation,
  title = {Approximation by Superpositions of a Sigmoidal Function},
  author = {Cybenko, G.},
  date = {1989-12-01},
  journaltitle = {Mathematics of Control, Signals and Systems},
  shortjournal = {Math. Control Signal Systems},
  volume = {2},
  number = {4},
  pages = {303--314},
  issn = {1435-568X},
  doi = {10/dp3968},
  abstract = {In this paper we demonstrate that finite linear combinations of compositions of a fixed, univariate function and a set of affine functionals can uniformly approximate any continuous function ofn real variables with support in the unit hypercube; only mild conditions are imposed on the univariate function. Our results settle an open question about representability in the class of single hidden layer neural networks. In particular, we show that arbitrary decision regions can be arbitrarily well approximated by continuous feedforward neural networks with only a single internal, hidden layer and any continuous sigmoidal nonlinearity. The paper discusses approximation properties of other possible types of nonlinearities that might be implemented by artificial neural networks.},
  langid = {english},
  file = {/var/home/hannes/Zotero/storage/J5PSSVFS/Cybenkot - Approximation by superpositions of a sigmoidal fun.pdf}
}

@online{davidwilliams2009schistosoma,
  title = {Schistosoma 20041-300},
  author = {{David Williams}},
  date = {2009-09-02},
  url = {https://commons.wikimedia.org/wiki/File:Schistosoma_20041-300.jpg},
  urldate = {2022-01-31},
  langid = {english},
  file = {/var/home/hannes/Zotero/storage/YFHW8896/FileSchistosoma_20041-300.html}
}

@incollection{dibucchianico2008coefficient,
  title = {Coefficient of Determination ({{R2}})},
  booktitle = {Encyclopedia of Statistics in Quality and Reliability},
  author = {Di Bucchianico, Alessandro},
  date = {2008},
  eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/9780470061572.eqr173},
  publisher = {{John Wiley \& Sons, Ltd}},
  doi = {10.1002/9780470061572.eqr173},
  abstract = {Abstract Coefficient of determination is a goodness-of-fit measure for models based on the proportion of explained variance. Variants of the coefficient of determination and pitfalls in the use of it are explained. The relation with the multiple correlation coefficient is explained.},
  isbn = {978-0-470-06157-2},
  keywords = {analysis of variance,coefficient of determination,lack of fit,linear regression},
  file = {/var/home/hannes/Zotero/storage/23KCQRIW/Di Bucchianico_2008_Coefficient of determination (R2).pdf}
}

@online{dpdx2017trichuriasis,
  title = {Trichuriasis},
  author = {DPDx},
  date = {2017-12-19},
  url = {https://web.archive.org/web/20210416192729/https://www.cdc.gov/dpdx/ascariasis/index.html},
  urldate = {2022-01-27},
  langid = {american}
}

@online{dpdx2019ascariasis,
  title = {Ascariasis},
  author = {DPDx},
  date = {2019-07-19},
  url = {https://web.archive.org/web/20210416192729/https://www.cdc.gov/dpdx/ascariasis/index.html},
  urldate = {2022-01-27},
  langid = {american}
}

@online{dpdx2019hookworm,
  title = {Hookworm ({{Intestinal}})},
  author = {DPDx},
  date = {2019-09-17},
  url = {https://web.archive.org/web/20211111192750/https://www.cdc.gov/dpdx/hookworm/index.html},
  urldate = {2022-01-27},
  langid = {american}
}

@online{dpdx2019schistosomiasis,
  title = {Schistosomiasis},
  author = {DPDx},
  date = {2019-08-14T12:36:15Z/},
  url = {https://web.archive.org/web/20220121161232/https://www.cdc.gov/dpdx/schistosomiasis/index.html},
  urldate = {2022-01-27},
  langid = {american},
  keywords = {Neglected Tropical Diseases,schistosoma,Schistosome,Schistosomiasis,Schistosomiasis - diagnosis}
}

@article{el-gabry2014wholeslide,
  title = {Whole-Slide Imaging: Widening the Scope of Cytopathology},
  shorttitle = {Whole-Slide Imaging},
  author = {El-Gabry, Ehab A. and Parwani, Anil V. and Pantanowitz, Liron},
  date = {2014-12-01},
  journaltitle = {Diagnostic Histopathology},
  shortjournal = {Diagnostic Histopathology},
  series = {Mini-{{Symposium}}: {{Whole-Slide Imaging}} in {{Pathology}}},
  volume = {20},
  number = {12},
  pages = {456--461},
  issn = {1756-2317},
  doi = {10/gn9z7h},
  abstract = {Whole slide imaging (WSI) is broadening the scope of cytopathology. Whole slide images are being used for telecytology, quality assurance activities (e.g. proficiency testing) and teaching (e.g. digital teaching sets and online virtual atlases). Progress in WSI technology that permits high resolution scanning, z-stacking, and hybrid robotic devices has encouraged the use of this imaging modality for cytology practice, education and research. However, widespread adoption in cytology still depends on overcoming barriers unrelated to cytology and challenges directly related to digitizing cytopathology slides. The aim of this article is to review WSI technology, applications and limitations specific to cytopathology.},
  langid = {english},
  keywords = {cytology,digital pathology,informatics,proficiency testing,telecytology,whole slide imaging,z-stacking},
  file = {/var/home/hannes/Zotero/storage/P79TNQF4/El-Gabry et al. - 2014 - Whole-slide imaging widening the scope of cytopat.pdf;/var/home/hannes/Zotero/storage/LC3FU4UH/S1756231714001753.html}
}

@video{etteplan2021fighting,
  title = {Fighting Intestinal Parasites by {{Jonson}} \& {{Johnson}} and {{Etteplan}}},
  editor = {{Etteplan}},
  date = {2021-07-10},
  url = {https://www.youtube.com/watch?v=w4tcILkQ6vg},
  urldate = {2022-04-25},
  abstract = {Johnson \& Johnson’s Global Public Health team is battling parasite infection on a global scale through mass drug administration. In order to further increase the effectiveness of the mass drug administration, new methods for screening and analysis are needed. A collaboration with Etteplan might prove a very important step towards increasing the scale, speed and reliability of the testing procedures.},
  editortype = {director}
}

@online{etteplanoyjengineering,
  title = {Engineering Company with a {{Difference}}},
  author = {{Etteplan Oyj}},
  url = {https://www.etteplan.com/},
  urldate = {2022-04-25},
  abstract = {We are a progressive group of over 3,800 global engineering specialists who are working to spark positive change in the world of engineering.},
  langid = {english},
  organization = {{Etteplan}},
  file = {/var/home/hannes/Zotero/storage/2AAJ8Q43/www.etteplan.com.html}
}

@article{feasey2010neglected,
  title = {Neglected Tropical Diseases},
  author = {Feasey, N. and Wansbrough-Jones, M. and Mabey, D. C. W. and Solomon, A. W.},
  date = {2010-03-01},
  journaltitle = {British Medical Bulletin},
  shortjournal = {British Medical Bulletin},
  volume = {93},
  number = {1},
  pages = {179--200},
  issn = {0007-1420, 1471-8391},
  doi = {10/fm3j5b},
  abstract = {Introduction: The neglected tropical diseases (NTDs) are infectious diseases that principally impact the world’s poorest people. They have been neglected for decades, initially as part of a general disregard for the developing world, and more recently due to the intensity of focus on HIV/AIDS, tuberculosis and malaria. Sources of data: Primary research and review articles were selected for inclusion using searches of PubMed and our existing collections. Results: There have been recent notable successes in NTD control. Dracunculiasis is approaching eradication. Leprosy and onchocerciasis are in decline. There are ambitious plans to eliminate trachoma and lymphatic filariasis. Investment in NTD control has high rates of economic return. Conclusion: Although there are proven strategies to control several NTDs, these diseases continue to cause a massive burden of morbidity. There is urgent need for more basic and operational research, drug and vaccine development, and greater prioritization by governments and international agencies.},
  langid = {english},
  keywords = {ascaris,hookworm,Neglected Tropical Diseases,schistosoma,whipworm},
  file = {/var/home/hannes/Zotero/storage/QZEMMS7X/Feasey et al. - 2010 - Neglected tropical diseases.pdf}
}

@article{ghaznavi2013digital,
  title = {Digital {{Imaging}} in {{Pathology}}: {{Whole-Slide Imaging}} and {{Beyond}}},
  shorttitle = {Digital {{Imaging}} in {{Pathology}}},
  author = {Ghaznavi, Farzad and Evans, Andrew and Madabhushi, Anant and Feldman, Michael},
  date = {2013-01-24},
  journaltitle = {Annual Review of Pathology: Mechanisms of Disease},
  shortjournal = {Annu. Rev. Pathol. Mech. Dis.},
  volume = {8},
  number = {1},
  pages = {331--359},
  issn = {1553-4006, 1553-4014},
  doi = {10/d73wcc},
  abstract = {Digital imaging in pathology has undergone an exponential period of growth and expansion catalyzed by changes in imaging hardware and gains in computational processing. Today, digitization of entire glass slides at near the optical resolution limits of light can occur in 60 s. Whole slides can be imaged in fluorescence or by use of multispectral imaging systems. Computational algorithms have been developed for cytometric analysis of cells and proteins in subcellular locations by use of multiplexed antibody staining protocols. Digital imaging is unlocking the potential to integrate primary image features into high-dimensional genomic assays by moving microscopic analysis into the digital age. This review highlights the emerging field of digital pathology and explores the methods and analytic approaches being developed for the application and use of these methods in clinical care and research settings.},
  langid = {english},
  file = {/var/home/hannes/Zotero/storage/T3ULMPVZ/Ghaznavi et al. - 2013 - Digital Imaging in Pathology Whole-Slide Imaging .pdf}
}

@article{hanna2019whole,
  title = {Whole Slide Imaging Equivalency and Efficiency Study: Experience at a Large Academic Center},
  shorttitle = {Whole Slide Imaging Equivalency and Efficiency Study},
  author = {Hanna, Matthew G. and Reuter, Victor E. and Hameed, Meera R. and Tan, Lee K. and Chiang, Sarah and Sigel, Carlie and Hollmann, Travis and Giri, Dilip and Samboy, Jennifer and Moradel, Carlos and Rosado, Andrea and Otilano, John R. and England, Christine and Corsale, Lorraine and Stamelos, Evangelos and Yagi, Yukako and Schüffler, Peter J. and Fuchs, Thomas and Klimstra, David S. and Sirintrapun, S. Joseph},
  date = {2019-07},
  journaltitle = {Modern Pathology},
  shortjournal = {Mod Pathol},
  volume = {32},
  number = {7},
  pages = {916--928},
  publisher = {{Nature Publishing Group}},
  issn = {1530-0285},
  doi = {10/gg3wtj},
  abstract = {Whole slide imaging is Food and Drug Administration-approved for primary diagnosis in the United States of America; however, relatively few pathology departments in the country have fully implemented an enterprise wide digital pathology system enabled for primary diagnosis. Digital pathology has significant potential to transform pathology practice with several published studies documenting some level of diagnostic equivalence between digital and conventional systems. However, whole slide imaging also has significant potential to disrupt pathology practice, due to the differences in efficiency of manipulating digital images vis-à-vis glass slides, and studies on the efficiency of actual digital pathology workload are lacking. Our randomized, equivalency and efficiency study aimed to replicate clinical workflow, comparing conventional microscopy to a complete digital pathology signout using whole slide images, evaluating the equivalency and efficiency of glass slide to whole slide image reporting, reflective of true pathology practice workloads in the clinical setting. All glass slides representing an entire day’s routine clinical signout workload for six different anatomic pathology subspecialties at Memorial Sloan Kettering Cancer Center were scanned on Leica Aperio AT2 at ×40 (0.25\,µm/pixel). Integration of whole slide images for each accessioned case is through an interface between the Leica eSlide manager database and the laboratory information system, Cerner CoPathPlus. Pathologists utilized a standard institution computer workstation and viewed whole slide images through an internally developed, vendor agnostic whole slide image viewer, named the “MSK Slide Viewer”. Subspecialized pathologists first reported on glass slides from surgical pathology cases using routine clinical workflow. Glass slides were de-identified, scanned, and re-accessioned in the laboratory information system test environment. After a washout period of 13 weeks, pathologists reported the same clinical workload using whole slide image integrated within the laboratory information system. Intraobserver equivalency metrics included top-line diagnosis, margin status, lymphovascular and/or perineural invasion, pathology stage, and the need to order ancillary testing (i.e., recuts, immunohistochemistry). Turnaround time (efficiency) evaluation was defined by the start of each case when opened in the laboratory information system and when the case was completed for that day (i.e., case sent to signout queue or pending ancillary studies). Eight pathologists participated from the following subspecialties: bone and soft tissue, genitourinary, gastrointestinal, breast, gynecologic, and dermatopathology. Glass slides signouts comprised of 204 cases, encompassing 2091 glass slides; and digital signouts comprised of 199 cases, encompassing 2073 whole slide images. The median whole slide image file size was 1.54\,GB; scan time/slide, 6\,min 24\,s; and scan area 32.1\,×\,18.52\,mm. Overall diagnostic equivalency (e.g., top-line diagnosis) was 99.3\% between digital and glass slide signout; however, signout using whole slide images showed a median overall 19\% decrease in efficiency per case. No significant difference by reader, subspecialty, or specimen type was identified. Our experience is the most comprehensive study to date and shows high intraobserver whole slide image to glass slide equivalence in reporting of true clinical workflows and workloads. Efficiency needs to improve for digital pathology to gain more traction among pathologists.},
  issue = {7},
  langid = {english},
  keywords = {Diagnosis,Pathology},
  file = {/var/home/hannes/Zotero/storage/MJS4TGZB/Hanna et al_2019_Whole slide imaging equivalency and efficiency study.pdf;/var/home/hannes/Zotero/storage/KLKKE2XA/s41379-019-0205-0.html}
}

@inproceedings{he2016deep,
  title = {Deep {{Residual Learning}} for {{Image Recognition}}},
  booktitle = {Proceedings of the {{IEEE}} Conference on Computer Vision and Pattern Recognition},
  author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  date = {2016},
  eprint = {1512.03385},
  eprinttype = {arxiv},
  pages = {770--778},
  location = {{Las Vegas, NV, USA}},
  doi = {10.1109/CVPR33180.2016},
  abstract = {Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers—8× deeper than VGG nets [41] but still having lower complexity. An ensemble of these residual nets achieves 3.57\% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers.},
  archiveprefix = {arXiv},
  eventtitle = {{{IEEE}} Conference on Computer Vision and Pattern Recognition},
  langid = {english},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,model,resnet},
  file = {/var/home/hannes/Zotero/storage/HH7IPDWJ/He et al. - 2015 - Deep Residual Learning for Image Recognition.pdf}
}

@article{hornik1991approximation,
  title = {Approximation Capabilities of Multilayer Feedforward Networks},
  author = {Hornik, Kurt},
  date = {1991-01-01},
  journaltitle = {Neural Networks},
  shortjournal = {Neural Networks},
  volume = {4},
  number = {2},
  pages = {251--257},
  issn = {0893-6080},
  doi = {10/dzwxkd},
  abstract = {We show that standard multilayer feedforward networks with as few as a single hidden layer and arbitrary bounded and nonconstant activation function are universal approximators with respect to Lp(μ) performance criteria, for arbitrary finite input environment measures μ, provided only that sufficiently many hidden units are available. If the activation function is continuous, bounded and nonconstant, then continuous mappings can be learned uniformly over compact input sets. We also give very general conditions ensuring that networks with sufficiently smooth activation functions are capable of arbitrarily accurate approximation to a function and its derivatives.},
  langid = {english},
  keywords = {() approximation,Activation function,Input environment measure,Multilayer feedforward networks,Smooth approximation,Sobolev spaces,Uniform approximation,Universal approximation capabilities},
  file = {/var/home/hannes/Zotero/storage/9YEDLE43/Hornik_1991_Approximation capabilities of multilayer feedforward networks.pdf}
}

@article{hosseini2019encoding,
  title = {Encoding Visual Sensitivity by {{MaxPol}} Convolution Filters for Image Sharpness Assessment},
  author = {Hosseini, M. S. and Zhang, Y. and Plataniotis, K. N.},
  date = {2019-09},
  journaltitle = {IEEE Transactions on Image Processing},
  volume = {28},
  number = {9},
  pages = {4510--4525},
  issn = {1057-7149},
  doi = {10.1109/TIP.2019.2906582}
}

@article{hosseini2020focus,
  title = {Focus {{Quality Assessment}} of {{High-Throughput Whole Slide Imaging}} in {{Digital Pathology}}},
  author = {Hosseini, Mahdi S. and Brawley-Hayes, Jasper A. Z. and Zhang, Yueyang and Chan, Lyndon and Plataniotis, Konstantinos N. and Damaskinos, Savvas},
  date = {2020-01},
  journaltitle = {IEEE Transactions on Medical Imaging},
  volume = {39},
  number = {1},
  pages = {62--74},
  issn = {1558-254X},
  doi = {10/gm8ghb},
  abstract = {One of the challenges facing the adoption of digital pathology workflows for clinical use is the need for automated quality control. As the scanners sometimes determine focus inaccurately, the resultant image blur deteriorates the scanned slide to the point of being unusable. Also, the scanned slide images tend to be extremely large when scanned at greater or equal 20X image resolution. Hence, for digital pathology to be clinically useful, it is necessary to use computational tools to quickly and accurately quantify the image focus quality and determine whether an image needs to be re-scanned. We propose a no-reference focus quality assessment metric specifically for digital pathology images that operate by using a sum of even-derivative filter bases to synthesize a human visual system-like kernel, which is modeled as the inverse of the lens' point spread function. This kernel is then applied to a digital pathology image to modify high-frequency image information deteriorated by the scanner's optics and quantify the focus quality at the patch level. We show in several experiments that our method correlates better with ground-truth z -level data than other methods, which is more computationally efficient. We also extend our method to generate a local slide-level focus quality heatmap, which can be used for automated slide quality control, and demonstrate the utility of our method for clinical scan quality control by comparison with subjective slide quality scores.},
  eventtitle = {{{IEEE Transactions}} on {{Medical Imaging}}},
  keywords = {digital pathology,Feature extraction,human visual system,Kernel,MaxPol derivative library,Measurement,Microscopy,No-reference focus quality assessment,out-of-focus heatmap,Pathology,Quality assessment,whole slide imaging},
  file = {/var/home/hannes/Zotero/storage/7BPBS5H7/Hosseini et al. - 2020 - Focus Quality Assessment of High-Throughput Whole .pdf;/var/home/hannes/Zotero/storage/F4YQJGTT/8725582.html}
}

@inproceedings{ioffe2015batch,
  title = {Batch Normalization: {{Accelerating}} Deep Network Training by Reducing Internal Covariate Shift},
  booktitle = {International Conference on Machine Learning},
  author = {Ioffe, Sergey and Szegedy, Christian},
  date = {2015},
  pages = {448--456},
  organization = {{PMLR}},
  keywords = {⛔ No DOI found},
  file = {/var/home/hannes/Zotero/storage/D25J3IP4/Ioffe and Szegedy - 2015 - Batch Normalization Accelerating Deep Network Tra.pdf}
}

@incollection{jamison2006helminth,
  title = {Helminth {{Infections}}: {{Soil-Transmitted Helminth Infections}} and {{Schistosomiasis}}},
  shorttitle = {Chapter 24. {{Helminth Infections}}},
  booktitle = {Disease {{Control Priorities}} in {{Developing Countries}} (2nd {{Edition}})},
  editor = {Jamison, Dean T. and Breman, Joel G. and Measham, Anthony R. and Alleyne, George and Claeson, Mariam and Evans, David B. and Jha, Prabhat and Mills, Anne and Musgrove, Philip},
  date = {2006-04-02},
  pages = {467--482},
  publisher = {{World Bank Publications}},
  doi = {10.1596/978-0-8213-6179-5/Chpt-24},
  isbn = {978-0-8213-6179-5},
  langid = {english},
  keywords = {ascaris,hookworm,Neglected Tropical Diseases,schistosoma,Soil-Transmitted Helminths,whipworm},
  file = {/var/home/hannes/Zotero/storage/8VE6JXLH/Jamison et al. - 2006 - Chapter 24. Helminth Infections Soil-Transmitted .pdf}
}

@article{jourdan2018soiltransmitted,
  title = {Soil-Transmitted Helminth Infections},
  author = {Jourdan, Peter Mark and Lamberton, Poppy H L and Fenwick, Alan and Addiss, David G},
  date = {2018-01},
  journaltitle = {The Lancet},
  shortjournal = {The Lancet},
  volume = {391},
  number = {10117},
  pages = {252--265},
  issn = {01406736},
  doi = {10/gczb9g},
  langid = {english},
  keywords = {ascaris,hookworm,Neglected Tropical Diseases,Soil-Transmitted Helminths,whipworm},
  file = {/var/home/hannes/Zotero/storage/7ZN2MNLC/Jourdan et al. - 2018 - Soil-transmitted helminth infections.pdf}
}

@article{kato1954comparative,
  title = {Comparative Examinations},
  author = {Kato, K and Miura, M},
  date = {1954},
  journaltitle = {Jpn J Parasitol},
  volume = {3},
  pages = {35},
  keywords = {⛔ No DOI found}
}

@article{kato1960correct,
  title = {A Correct Application of the Thick-Smear Technic with Cellophane Paper Cover},
  author = {Kato, K},
  date = {1960},
  journaltitle = {A pamphlet},
  pages = {1--9},
  keywords = {⛔ No DOI found}
}

@article{katz1972simple,
  title = {A Simple Device for Quantitative Stool Thick-Smear Technique in {{Schistosomiasis}} Mansoni},
  author = {Katz, N. and Chaves, A. and Pellegrino, J.},
  date = {1972},
  journaltitle = {Revista do Instituto de Medicina Tropical de São Paulo},
  volume = {14},
  number = {6},
  pages = {397--400},
  isbn = {0036-4665},
  langid = {english},
  keywords = {Feces,Female,Humans,Intestinal Diseases,Methods,Ovum,Parasite Egg Count - instrumentation,Parasitic - diagnosis,Schistosomiasis - diagnosis,Weights and Measures},
  file = {/var/home/hannes/Zotero/storage/6VXRRMFN/Katz et al. - 1972 - A simple device for quantitative stool thick-smear.pdf}
}

@article{kohlberger2019wholeslide,
  title = {Whole-Slide Image Focus Quality: {{Automatic}} Assessment and Impact on Ai Cancer Detection},
  shorttitle = {Whole-Slide Image Focus Quality},
  author = {Kohlberger, Timo and Liu, Yun and Moran, Melissa and Chen, Po-Hsuan Cameron and Brown, Trissia and Hipp, Jason D. and Mermel, Craig H. and Stumpe, Martin C.},
  date = {2019-01-01},
  journaltitle = {Journal of Pathology Informatics},
  volume = {10},
  number = {1},
  eprint = {31921487},
  eprinttype = {pmid},
  pages = {39},
  publisher = {{Medknow Publications}},
  issn = {2153-3539},
  doi = {10/gm9n9g},
  abstract = {{$<$}br{$>$}\textbf{Background:} Digital pathology enables remote access or consults and powerful image analysis algorithms. However, the slide digitization process can create artifacts such as out-of-focus (OOF). OOF is often only detected on careful review, potentially causing rescanning, and workflow delays. Although scan time operator screening for whole-slide OOF is feasible, manual screening for OOF affecting only parts of a slide is impractical. \textbf{Methods:} We developed a convolutional neural network (ConvFocus) to exhaustively localize and quantify the severity of OOF regions on digitized slides. ConvFocus was developed using our refined semi-synthetic OOF data generation process and evaluated using seven slides spanning three different tissue and three different stain types, each of which were digitized using two different whole-slide scanner models ConvFocus's predictions were compared with pathologist-annotated focus quality grades across 514 distinct regions representing 37,700 35 μm × 35 μm image patches, and 21 digitized “z-stack” WSIs that contain known OOF patterns. \textbf{Results:} When compared to pathologist-graded focus quality, ConvFocus achieved Spearman rank coefficients of 0.81 and 0.94 on two scanners and reproduced the expected OOF patterns from z-stack scanning. We also evaluated the impact of OOF on the accuracy of a state-of-the-art metastatic breast cancer detector and saw a consistent decrease in performance with increasing OOF. \textbf{Conclusions:} Comprehensive whole-slide OOF categorization could enable rescans before pathologist review, potentially reducing the impact of digitization focus issues on the clinical workflow. We show that the algorithm trained on our semi-synthetic OOF data generalizes well to real OOF regions across tissue types, stains, and scanners. Finally, quantitative OOF maps can flag regions that might otherwise be misclassified by image analysis algorithms, preventing OOF-induced errors.{$<$}br{$>$}},
  langid = {english},
  keywords = {ConvFocus,Deep Learning,Focus Quality Assessment,out of focus detection,related work},
  file = {/var/home/hannes/Zotero/storage/TPUQGMK8/Kohlberger et al. - 2019 - Whole-slide image focus quality Automatic assessm.pdf;/var/home/hannes/Zotero/storage/I46YGIVL/article.html}
}

@software{kuchelmeister2022focus,
  title = {Focus {{Annotator}}},
  author = {Kuchelmeister, Hannes F.},
  date = {2022-02-25},
  origdate = {2022-01-26T11:11:38Z},
  url = {https://github.com/13hannes11/focus_annotator},
  abstract = {This is a tool to annotate the focus plane of z-stacked images.},
  version = {0.1.1},
  keywords = {data-annotation,focus-stacking,microscopy,rust,z-stack}
}

@thesis{larsson2020development,
  type = {Examensarbete},
  title = {Development of Machine Learning Models for Object Identification of Parasite Eggs Using Microscopy},
  author = {Larsson, Joel and Hedberg, Rasmus},
  date = {2020},
  institution = {{Uppsala University}},
  location = {{Uppsala}},
  url = {http://urn.kb.se/resolve?urn=urn:nbn:se:uu:diva-414386},
  urldate = {2022-01-26},
  abstract = {Over one billion people in developing countries are afflicted by parasitic infections caused by soil-transmitted helminths. These infections are treatable with cheap and safe medicine that is widely available. However, diagnosis of these infections has proven to be a bottleneck by the fact that it is time-consuming, requires expensive equipment and trained personnel to be consistent and accurate. This study aimed to investigate the viability and performance of five machine learning models and a 'modular neural network' approach to localize and classify the following parasite eggs in microscopic images: Ascaris lumbricoides, Trichuris trichuria, Hookworm and Schistosoma mansoni. These models were implemented and evaluated on the Nvidia Jetson AGX Xavier to establish that they fulfilled the specifications of 95\textbackslash\% specificity and sensitivity, but also a speed requirement of 40000 images per 24 hours. The results show that R-FCN ResNet101 was the best model produced in this study, which performed the best on average. However, it did not fulfill the specifications entirely but is still considered a success due to being an improvement to the current implementation at Etteplan. Evaluation of the modular neural network approach would require further investigation to verify the performance of the system, but the results indicate it could be a possible improvement to the off-the-shelf machine learning models. To conclude, the study showed that the data and data infrastructure provided by Etteplan has proven to be a very powerful tool in training machine learning models to classify and localize parasite eggs in stool samples. However, expansion of the data to reduce the imbalance between the representations of the classes but also include more patient information could improve the training and evaluation process of the models.},
  langid = {english},
  pagetotal = {34},
  file = {/var/home/hannes/Zotero/storage/X4VAW9B4/Larsson and Hedberg - 2020 - Development of machine learning models for object .pdf}
}

@article{lee2008enhanced,
  title = {Enhanced Autofocus Algorithm Using Robust Focus Measure and Fuzzy Reasoning},
  author = {Lee, Sang-Yong and Kumar, Yogendera and Cho, Ji-Man and Lee, Sang-Won and Kim, Soo-Won},
  date = {2008},
  journaltitle = {IEEE Transactions on Circuits and Systems for Video Technology},
  volume = {18},
  number = {9},
  pages = {1237--1246},
  doi = {10.1109/TCSVT.2008.924105},
  file = {/var/home/hannes/Zotero/storage/7CQZIU2K/Lee et al_2008_Enhanced autofocus algorithm using robust focus measure and fuzzy reasoning.pdf}
}

@article{liang2019learning,
  title = {Learning to Autofocus Based on {{Gradient Boosting Machine}} for Optical Microscopy},
  author = {Liang, Yixiong and Yan, Meng and Tang, Zhihong and He, Zhujun and Liu, Jianfeng},
  date = {2019-12-01},
  journaltitle = {Optik},
  shortjournal = {Optik},
  volume = {198},
  pages = {163002},
  issn = {0030-4026},
  doi = {10.1016/j.ijleo.2019.163002},
  abstract = {Autofocus is an essential part of modern high-throughput optical microscopic imaging system, and the traditional passive autofocus algorithms such as hill climbing search are heuristics and therefore are slow and less accuracy. Instead of using the heuristics, in this paper we treat the autofocus as a regression problem and propose to learn a Gradient Boosting Machine (GBM) to predict the direction and step size simultaneously. We first leverage Fourier optical theory to explore the feasibility of predicting the step size and direction simultaneously with only one regressor. And then, inspired by Depth from Defocus (DFD), we design novel basic and combined features for faster and better autofocus. Finally, we comprehensively evaluate our methods on a dataset consisting of 2000 annotated images corresponding to 20 benchmarks of cell images. Our Defocus of Focus (DFF)-based autofocus shows improved accuracy over previous work from 97.1\% to 99.9\%, and significantly reduces the number of steps, achieving a 51.48\% relative improvement. Code and dataset will be made publicly available.},
  langid = {english},
  keywords = {autofocus,Autofocus,Depth from Defocus,Depth from Focus,Gradient Boosting Machine,related work},
  file = {/var/home/hannes/Zotero/storage/4Z7JWJAP/S0030402619308794.html}
}

@incollection{liu2016computer,
  title = {Computer Vision in Big Data Applications},
  booktitle = {Computational and {{Statistical Methods}} for {{Analysing Big Data}} with {{Applications}}},
  author = {Liu, Shen and McGree, James and Ge, Zongyuan and Xie, Yang},
  editor = {Liu, Shen and McGree, James and Ge, Zongyuan and Xie, Yang},
  date = {2016-01-01},
  pages = {57--85},
  publisher = {{Academic Press}},
  location = {{San Diego}},
  doi = {10.1016/B978-0-12-803732-4.00004-0},
  abstract = {This chapter focuses on computer vision techniques, which have numerous applications in many fields such as medical imaging diagnosis and process, face recognition or verification system, video camera surveillance, transportation, etc. Over the past decade, computer vision has been proven successful in solving real-life problems. For instance, the registration plate of a vehicle using tollway is identified from the picture taken by the monitoring camera, and then the corresponding driver will be notified and billed automatically. In this chapter, we will discuss how big data facilitate the development of computer vision technologies, and how these technologies can be applied in big data applications. Especially, we will discuss the-state-of-the-art deep learning algorithms and demonstrate how this methodology can be applied to solve large scale image recognition problems. A tutorial will be given at the end of this chapter for the purpose of illustration.},
  isbn = {978-0-12-803732-4},
  langid = {english},
  keywords = {Classification,Convolutional neural networks,Deep learning,ImageNet,Machine learning,Robotics},
  file = {/var/home/hannes/Zotero/storage/DRHFXPJ5/Liu et al_2016_Computer vision in big data applications.pdf;/var/home/hannes/Zotero/storage/I5HYVHBJ/B9780128037324000040.html}
}

@article{mateos-perez2012comparative,
  title = {Comparative Evaluation of Autofocus Algorithms for a Real-Time System for Automatic Detection of {{Mycobacterium}} Tuberculosis},
  author = {Mateos-Pérez, José María and Redondo, Rafael and Nava, Rodrigo and Valdiviezo, Juan C. and Cristóbal, Gabriel and Escalante-Ramírez, Boris and Ruiz-Serrano, María Jesús and Pascau, Javier and Desco, Manuel},
  date = {2012-03},
  journaltitle = {Cytometry Part A},
  shortjournal = {Cytometry},
  volume = {81A},
  number = {3},
  pages = {213--221},
  issn = {15524922},
  doi = {10.1002/cyto.a.22020},
  langid = {english},
  keywords = {autofocus,traditional},
  file = {/var/home/hannes/Zotero/storage/HR46HK4Q/Mateos-Pérez et al. - 2012 - Comparative evaluation of autofocus algorithms for.pdf}
}

@article{mbongngwese2020diagnostic,
  title = {Diagnostic {{Techniques}} of {{Soil-Transmitted Helminths}}: {{Impact}} on {{Control Measures}}},
  shorttitle = {Diagnostic {{Techniques}} of {{Soil-Transmitted Helminths}}},
  author = {Mbong Ngwese, Mirabeau and Prince Manouana, Gédéon and Nguema Moure, Paul Alvyn and Ramharter, Michael and Esen, Meral and Adégnika, Ayola Akim},
  date = {2020-06},
  journaltitle = {Tropical Medicine and Infectious Disease},
  volume = {5},
  number = {2},
  pages = {93},
  publisher = {{Multidisciplinary Digital Publishing Institute}},
  issn = {2414-6366},
  doi = {10/gpbg2z},
  abstract = {Soil-transmitted helminth (STH) infections are common in the tropical and subtropical countries. The burden of disease is highest in endemic areas with limited access to good quality water supply and poor sanitary conditions. Major approaches to control and reduce morbidity caused by worm infections include the periodic deworming of pre-school and school-aged children with anthelminthic drugs. Population-based studies and individual patient management including interventional studies can only be successful when accurate diagnostic techniques are used. The lack of appropriate diagnostic tools providing accurate results concerning both infectious status and intensity of infection—as these two factors vary in regions of low infection intensities—is a major challenge. Currently, available techniques show limited sensitivity and specificity and as such, a combination of several techniques is usually used to diagnose the large variety of parasite species. The objective of this review was to describe the advantages and disadvantages of the different available techniques for the diagnosis of STH infections and to highlight their use in control programs.},
  issue = {2},
  langid = {english},
  keywords = {control measures,diagnostics,intestinal helminths,soil-transmitted helminths},
  file = {/var/home/hannes/Zotero/storage/HPCFZQQW/Mbong Ngwese et al_2020_Diagnostic Techniques of Soil-Transmitted Helminths.pdf;/var/home/hannes/Zotero/storage/4A5TB6PI/htm.html}
}

@article{moleslopez2013automated,
  title = {An Automated Blur Detection Method for Histological Whole Slide Imaging},
  author = {Moles Lopez, Xavier and D'Andrea, Etienne and Barbot, Paul and Bridoux, Anne-Sophie and Rorive, Sandrine and Salmon, Isabelle and Debeir, Olivier and Decaestecker, Christine},
  date = {2013-12},
  journaltitle = {PLOS ONE},
  volume = {8},
  number = {12},
  pages = {1--11},
  publisher = {{Public Library of Science}},
  doi = {10.1371/journal.pone.0082710},
  abstract = {Whole slide scanners are novel devices that enable high-resolution imaging of an entire histological slide. Furthermore, the imaging is achieved in only a few minutes, which enables image rendering of large-scale studies involving multiple immunohistochemistry biomarkers. Although whole slide imaging has improved considerably, locally poor focusing causes blurred regions of the image. These artifacts may strongly affect the quality of subsequent analyses, making a slide review process mandatory. This tedious and time-consuming task requires the scanner operator to carefully assess the virtual slide and to manually select new focus points. We propose a statistical learning method that provides early image quality feedback and automatically identifies regions of the image that require additional focus points.}
}

@article{nelwan2019schistosomiasis,
  title = {Schistosomiasis: {{Life Cycle}}, {{Diagnosis}}, and {{Control}}},
  shorttitle = {Schistosomiasis},
  author = {Nelwan, Martin L.},
  date = {2019-01-01},
  journaltitle = {Current Therapeutic Research},
  shortjournal = {Current Therapeutic Research},
  volume = {91},
  pages = {5--9},
  issn = {0011-393X},
  doi = {10/gmcq9x},
  abstract = {Background Human schistosomiasis is a parasitic disease caused by blood-worms that infect multiple organs, including the liver, intestine, bladder, and urethra. This disease may be eliminated with Praziquantel, vaccines, and gene therapy. Aims In this review, the author describes the progress in a study of schistosomiasis that focused on the life cycle, diagnosis, and control. Methodology The author searched the PubMed Database at NCBI for articles on schistosomiasis published between 2014 and 2018. All articles were open access and in English. Results The life cycle of this parasites involve two hosts: snails and mammals. Manifestations of schistosomiasis can be acute or chronic. Clinical manifestations of acute schistosomiasis can include fever and headache. Symptoms of chronic infections can include dysuria and hyperplasia. Infection can occur in several sites including the bile ducts, intestine, and bladder. The different sites of infection and symptoms seen are related to which of the species involved. Five species can infect humans. The three most commons are S. haematobium, S. japonicum, and S. mansoni. Detection tools for people with schistosomiasis can include the Kato-Katz and PCR. Praziquantel is at present the only effective treatment of this disease. In the future, vaccination or gene therapy may be used. Conclusion Kato-Katz and PCR are tools for detecting schistosomiasis on humans. Praziquantel, diagnosis, vaccines, and gene therapy are useful methods for eliminating schistosomiasis.},
  langid = {english},
  keywords = {Neglected Tropical Diseases,Praziquantel,schistosoma,Schistosome,Schistosomiasis},
  file = {/var/home/hannes/Zotero/storage/GEVUJRPW/Nelwan - 2019 - Schistosomiasis Life Cycle, Diagnosis, and Contro.pdf;/var/home/hannes/Zotero/storage/BJRYXUJL/S0011393X19300098.html}
}

@book{nielsen2015neural,
  title = {Neural {{Networks}} and {{Deep Learning}}},
  author = {Nielsen, Michael A.},
  date = {2015},
  url = {http://neuralnetworksanddeeplearning.com/},
  langid = {english},
  keywords = {⛔ No DOI found},
  file = {/var/home/hannes/Zotero/storage/9RRV2QLL/Nielsen - Neural Networks and Deep Learning.pdf}
}

@article{oliveira2000haemozoin,
  title = {Haemozoin in {{Schistosoma}} Mansoni},
  author = {Oliveira, Marcus F and d' Avila, Joana C.P and Torres, Christiane R and Oliveira, Pedro L and Tempone, Antônio J and Rumjanek, Franklin D and Braga, Cláudia M.S and Silva, José R and Dansa-Petretski, Marı́lvia and Oliveira, Marco A and de Souza, Wanderley and Ferreira, Sérgio T},
  options = {useprefix=true},
  date = {2000-11},
  journaltitle = {Molecular and Biochemical Parasitology},
  shortjournal = {Molecular and Biochemical Parasitology},
  volume = {111},
  number = {1},
  pages = {217--221},
  issn = {01666851},
  doi = {10/dz9sz4},
  langid = {english},
  keywords = {Neglected Tropical Diseases,schistosoma},
  file = {/var/home/hannes/Zotero/storage/4ZCCEREK/Oliveira et al. - 2000 - Haemozoin in Schistosoma mansoni.pdf}
}

@article{osibote2010automated,
  title = {Automated Focusing in Bright-Field Microscopy for Tuberculosis Detection: {{BRIGHT-FIELD AUTOFOCUSING FOR TUBERCULOSIS DETECTION}}},
  shorttitle = {Automated Focusing in Bright-Field Microscopy for Tuberculosis Detection},
  author = {Osibote, O.A. and Dendere, R. and Krishnan, S. and Douglas, T.S.},
  date = {2010-11},
  journaltitle = {Journal of Microscopy},
  volume = {240},
  number = {2},
  pages = {155--163},
  issn = {00222720},
  doi = {10/fcftsf},
  langid = {english},
  file = {/var/home/hannes/Zotero/storage/CGEQ4856/Osibote et al. - 2010 - Automated focusing in bright-field microscopy for .pdf}
}

@unpublished{paszke2019pytorch,
  title = {{{PyTorch}}: {{An Imperative Style}}, {{High-Performance Deep Learning Library}}},
  shorttitle = {{{PyTorch}}},
  author = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and Köpf, Andreas and Yang, Edward and DeVito, Zach and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith},
  date = {2019-12-03},
  eprint = {1912.01703},
  eprinttype = {arxiv},
  primaryclass = {cs, stat},
  url = {http://arxiv.org/abs/1912.01703},
  urldate = {2022-03-28},
  abstract = {Deep learning frameworks have often focused on either usability or speed, but not both. PyTorch is a machine learning library that shows that these two goals are in fact compatible: it provides an imperative and Pythonic programming style that supports code as a model, makes debugging easy and is consistent with other popular scientific computing libraries, while remaining efficient and supporting hardware accelerators such as GPUs. In this paper, we detail the principles that drove the implementation of PyTorch and how they are reflected in its architecture. We emphasize that every aspect of PyTorch is a regular Python program under the full control of its user. We also explain how the careful and pragmatic implementation of the key components of its runtime enables them to work together to achieve compelling performance. We demonstrate the efficiency of individual subsystems, as well as the overall speed of PyTorch on several common benchmarks.},
  archiveprefix = {arXiv},
  version = {1},
  keywords = {⛔ No DOI found,Computer Science - Machine Learning,Computer Science - Mathematical Software,Libraries,Statistics - Machine Learning},
  file = {/var/home/hannes/Zotero/storage/S58PF8J4/Paszke et al_2019_PyTorch.pdf;/var/home/hannes/Zotero/storage/VVY4J3KQ/1912.html}
}

@article{pearson1909determination,
  title = {Determination of the Coefficient of Correlation},
  author = {Pearson, Karl},
  date = {1909},
  journaltitle = {Science (New York, N.Y.)},
  shortjournal = {Science},
  volume = {30},
  number = {757},
  eprint = {1635783},
  eprinttype = {jstor},
  pages = {23--25},
  publisher = {{American Association for the Advancement of Science}},
  issn = {00368075, 10959203},
  doi = {10.1126/science.30.757.23}
}

@incollection{profillidis2019chapter,
  title = {Chapter 5 - Statistical Methods for Transport Demand Modeling},
  booktitle = {Modeling of Transport Demand},
  author = {Profillidis, V.A. and Botzoris, G.N.},
  editor = {Profillidis, V.A. and Botzoris, G.N.},
  date = {2019},
  pages = {163--224},
  publisher = {{Elsevier}},
  doi = {10.1016/B978-0-12-811513-8.00005-4},
  abstract = {This chapter deals with statistical methods, and more particularly with simple and multiple regression analysis, which are the basic tool when correlating transport demand to factors (such as time, cost, etc.) affecting it. After an overview of fundamentals of statistics such as terms, measures, hypothesis testing, probability distribution, and stationarity, the mathematical expression of the simple and multiple linear regression and the estimation of the various regression coefficients and the error term with the use of the ordinary least squares method are presented. Pearson correlation coefficient, coefficient of determination, and adjusted coefficient of determination as measures for the degree of correlation between one dependent and one or more independent variable(s) are analyzed. Tests of the significance of the coefficients of a regression analysis (Student's t-test and F-test) are presented afterward. Multicollinearity (correlation between independent variables), its detection, and techniques of removal are identified. The various characteristics and properties of residuals of a linear regression are surveyed with the help of the appropriate tests: probability distribution (skewness and kurtosis, Jarque–Bera test), influence of residuals and determination of outliers (Cook's distance), existence or not of serial correlation in the residuals (Durbin–Watson test, Durbin's h-test, Breusch–Godfrey Lagrange Multiplier test, Ljung–Box test). The various tests for the detection of heteroscedasticity in a regression analysis are analyzed: Breusch–Pagan test, Glesjer test, Harvey–Godfrey test, White test, autoregressive conditional heteroscedasticity test. Next, the various criteria for the evaluation of the forecasting accuracy of calibrated models are categorized, among them the Theil's inequality coefficient. All the above analysis, methods, tests, and criteria are extensively put into practice in a specific example of multiple linear regression analysis for the construction of an econometric model for transport demand.},
  isbn = {978-0-12-811513-8},
  keywords = {Coefficient of determination,Durbin–Watson test,Error,F-test,Forecasting accuracy,Heteroscedasticity,Homoscedasticity,Multicollinearity,Multivariate,Outlier,Pearson correlation coefficient,Regression,Regression coefficient,Residual,Serial correlation,Skewness and kurtosis,Stationarity,Student's t-test,Theil's inequality coefficient}
}

@incollection{profillidis2019statistical,
  title = {Statistical {{Methods}} for {{Transport Demand Modeling}}},
  booktitle = {Modeling of {{Transport Demand}}},
  author = {Profillidis, V.A. and Botzoris, G.N.},
  date = {2019},
  pages = {163--224},
  publisher = {{Elsevier}},
  doi = {10.1016/B978-0-12-811513-8.00005-4},
  isbn = {978-0-12-811513-8},
  langid = {english},
  file = {/var/home/hannes/Zotero/storage/WDBMZU32/Profillidis and Botzoris - 2019 - Statistical Methods for Transport Demand Modeling.pdf}
}

@article{redondo2012autofocus,
  title = {Autofocus Evaluation for Brightfield Microscopy Pathology},
  author = {Redondo, Rafael and Cristóbal, Gabriel and Garcia, Gloria Bueno and Deniz, Oscar and Salido, Jesus and Fernandez, Maria del Milagro and Vidal, Juan and Valdiviezo, Juan Carlos and Nava, Rodrigo and Escalante-Ramírez, Boris and Garcia-Rojo, Marcial},
  date = {2012-03},
  journaltitle = {Journal of Biomedical Optics},
  shortjournal = {JBO},
  volume = {17},
  number = {3},
  pages = {036008},
  publisher = {{SPIE}},
  issn = {1083-3668, 1560-2281},
  doi = {10.1117/1.JBO.17.3.036008},
  abstract = {An essential and indispensable component of automated microscopy framework is the automatic focusing system, which determines the in-focus position of a given field of view by searching the maximum value of a focusing function over a range of z-axis positions. The focus function and its computation time are crucial to the accuracy and efficiency of the system. Sixteen focusing algorithms were analyzed for histological and histopathological images. In terms of accuracy, results have shown an overall high performance by most of the methods. However, we included in the evaluation study other criteria such as computational cost and focusing curve shape which are crucial for real-time applications and were used to highlight the best practices.},
  keywords = {autofocus,Microscopy,related work},
  file = {/var/home/hannes/Zotero/storage/AZKQXKIR/Redondo et al_2012_Autofocus evaluation for brightfield microscopy pathology.pdf;/var/home/hannes/Zotero/storage/ISZAUL48/1.JBO.17.3.036008.html}
}

@inproceedings{riba2020kornia,
  title = {Kornia: An Open Source Differentiable Computer Vision Library for {{PyTorch}}},
  author = {Riba, E. and Mishkin, D. and Ponsa, D. and Rublee, E. and Bradski, G.},
  date = {2020},
  pages = {3663--3672},
  publisher = {{IEEE}},
  location = {{Snowmass, CO, USA}},
  doi = {10.1109/WACV45572.2020.9093363},
  eventtitle = {{{IEEE Winter Conference}} on {{Applications}} of {{Computer Vision}} ({{WACV}})},
  keywords = {⛔ No DOI found,Libraries},
  file = {/var/home/hannes/Zotero/storage/2UXTKP46/E. Riba, D. Mishkin_Bradski_2020_Kornia.pdf}
}

@article{rosenblatt1958perceptron,
  title = {The Perceptron: {{A}} Probabilistic Model for Information Storage and Organization in the Brain.},
  shorttitle = {The Perceptron},
  author = {Rosenblatt, F.},
  date = {1958},
  journaltitle = {Psychological Review},
  shortjournal = {Psychological Review},
  volume = {65},
  number = {6},
  pages = {386--408},
  issn = {1939-1471, 0033-295X},
  doi = {10/fg6wr5},
  langid = {english},
  keywords = {machine learning,neural networks,perceptron},
  file = {/var/home/hannes/Zotero/storage/5M7QL6CU/Rosenblatt - 1958 - The perceptron A probabilistic model for informat.pdf}
}

@article{senaras2018deepfocus,
  title = {{{DeepFocus}}: {{Detection}} of out-of-Focus Regions in Whole Slide Digital Images Using Deep Learning},
  shorttitle = {{{DeepFocus}}},
  author = {Senaras, Caglar and Niazi, M. Khalid Khan and Lozanski, Gerard and Gurcan, Metin N.},
  editor = {Lo, Chung-Ming},
  date = {2018-10-25},
  journaltitle = {PLOS ONE},
  shortjournal = {PLoS ONE},
  volume = {13},
  number = {10},
  pages = {e0205387},
  issn = {1932-6203},
  doi = {10/gm9n8p},
  langid = {english},
  keywords = {Deep Learning,DeepFocus,out of focus detection,Pathology,related work},
  file = {/var/home/hannes/Zotero/storage/45DQQNHY/Senaras et al. - 2018 - DeepFocus Detection of out-of-focus regions in wh.pdf}
}

@article{sharma2020activation,
  title = {Activation {{Functions}} in {{Neural Networks}}},
  author = {Sharma, Siddharth and Sharma, Simone and Scholar, UG and Athaiya, Anidhya},
  date = {2020},
  volume = {4},
  number = {12},
  pages = {7},
  abstract = {Artificial Neural Networks are inspired from the human brain and the network of neurons present in the brain. The information is processed and passed on from one neuron to another through neuro synaptic junctions. Similarly, in artificial neural networks there are different layers of cells arranged and connected to each other. The output/information from the inner layers of the neural network are passed on to the next layers and finally to the outermost layer which gives the output. The input to the outer layer is provided nonlinearity to inner layers’ output so that it can be further processed. In an Artificial Neural Network, activation functions are very important as they help in learning and making sense of non-linear and complicated mappings between the inputs and corresponding outputs.},
  langid = {english},
  file = {/var/home/hannes/Zotero/storage/RIX7DP2C/Sharma et al. - 2020 - Activation Functions in Neural Networks.pdf}
}

@book{shih2010image,
  title = {Image Processing and Pattern Recognition: Fundamentals and Techniques},
  author = {Shih, Frank Y},
  date = {2010},
  publisher = {{John Wiley \& Sons Inc.}},
  isbn = {978-0-470-59041-6},
  langid = {english},
  pagetotal = {325},
  file = {/var/home/hannes/Zotero/storage/ZE4KZA7B/Shih - Image Processing and Pattern Recognition.pdf}
}

@article{spearman1904proof,
  title = {The {{Proof}} and {{Measurement}} of {{Association}} between {{Two Things}}},
  author = {Spearman, C.},
  date = {1904},
  journaltitle = {The American journal of psychology},
  volume = {15},
  number = {1},
  pages = {72--101},
  doi = {10.2307/1412159},
  isbn = {0002-9556},
  langid = {english},
  keywords = {Accidents,Children,Coincidence,Correlations,Error rates,Fatigue,Randomness,Series convergence,Transcriptional regulatory elements,Uniformity},
  file = {/var/home/hannes/Zotero/storage/ET6VXHSI/Spearman_1904_The Proof and Measurement of Association between Two Things.pdf}
}

@inproceedings{szegedy2015going,
  title = {Going Deeper with Convolutions},
  booktitle = {Proceedings of the {{IEEE}} Conference on Computer Vision and Pattern Recognition ({{CVPR}})},
  author = {Szegedy, Christian and Liu, Wei and Jia, Yangqing and Sermanet, Pierre and Reed, Scott and Anguelov, Dragomir and Erhan, Dumitru and Vanhoucke, Vincent and Rabinovich, Andrew},
  date = {2015-06},
  file = {/var/home/hannes/Zotero/storage/LLFGABVY/Szegedy et al_2015_Going deeper with convolutions.pdf}
}

@inproceedings{szegedy2016rethinking,
  title = {Rethinking the Inception Architecture for Computer Vision},
  booktitle = {2016 {{IEEE}} Conference on Computer Vision and Pattern Recognition ({{CVPR}})},
  author = {Szegedy, Christian and Vanhoucke, Vincent and Ioffe, Sergey and Shlens, Jon and Wojna, Zbigniew},
  date = {2016},
  pages = {2818--2826},
  doi = {10.1109/CVPR.2016.308},
  keywords = {inception},
  file = {/var/home/hannes/Zotero/storage/APFIM87B/Szegedy et al_2016_Rethinking the inception architecture for computer vision.pdf}
}

@incollection{teuwen2020convolutional,
  title = {Convolutional Neural Networks},
  booktitle = {Handbook of Medical Image Computing and Computer Assisted Intervention},
  author = {Teuwen, Jonas and Moriakov, Nikita},
  date = {2020},
  series = {The {{Elsevier}} and {{MICCAI Society Book Series}}},
  pages = {481--501},
  publisher = {{Elsevier}},
  abstract = {In this chapter we introduce convolutional neural networks by starting with multilinear perceptrons, and proceed by explaining backpropagation. Using this we proceed to convolutional neural networks, explain the concept of convolutions, and provide practical methodologies to train such networks in the classification and segmentation setting.},
  isbn = {978-0-12-816176-0},
  keywords = {Backpropagation,Convnets,Convolutional neural networks,Multilinear perceptron},
  file = {/var/home/hannes/Zotero/storage/9RH5LZQT/Teuwen_Moriakov_2020_Convolutional neural networks.pdf}
}

@article{vollath1988influence,
  title = {The Influence of the Scene Parameters and of Noise on the Behaviour of Automatic Focusing Algorithms},
  author = {Vollath, D.},
  date = {1988},
  journaltitle = {Journal of Microscopy},
  volume = {151},
  number = {2},
  eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1365-2818.1988.tb04620.x},
  pages = {133--146},
  doi = {10.1111/j.1365-2818.1988.tb04620.x},
  abstract = {ABSTRACT A systematic study is presented of the properties of autofocus criteria. Special importance is attributed to their behaviour with respect to noise, working range and image sharpness, whose reproducibility has been investigated. It can be demonstrated that autofocus algorithms have either a large working range and do not focus in an unambiguous way or vice versa. From considerations of the properties of autofocus algorithms two novel algorithms have been developed which are insensitive to noise. One of these algorithms is characterized by a particularly large working range, whereas the other is capable of achieving maximum sharpness in a reproducible manner.},
  keywords = {Autofocus algorithms,scene parameters},
  file = {/var/home/hannes/Zotero/storage/XQ3PQZMC/Vollath_1988_The influence of the scene parameters and of noise on the behaviour of.pdf}
}

@inproceedings{wang2020focuslitenn,
  title = {{{FocusLiteNN}}: {{High Efficiency Focus Quality Assessment}} for {{Digital Pathology}}},
  shorttitle = {{{FocusLiteNN}}},
  booktitle = {Medical {{Image Computing}} and {{Computer Assisted Intervention}} – {{MICCAI}} 2020},
  author = {Wang, Zhongling and Hosseini, Mahdi S. and Miles, Adyn and Plataniotis, Konstantinos N. and Wang, Zhou},
  editor = {Martel, Anne L. and Abolmaesumi, Purang and Stoyanov, Danail and Mateus, Diana and Zuluaga, Maria A. and Zhou, S. Kevin and Racoceanu, Daniel and Joskowicz, Leo},
  date = {2020},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {403--413},
  publisher = {{Springer International Publishing}},
  location = {{Cham}},
  doi = {10/gnpd37},
  abstract = {Out-of-focus microscopy lens in digital pathology is a critical bottleneck in high-throughput Whole Slide Image (WSI) scanning platforms, for which pixel-level automated Focus Quality Assessment (FQA) methods are highly desirable to help significantly accelerate the clinical workflows. Existing FQA methods include both knowledge-driven and data-driven approaches. While data-driven approaches such as Convolutional Neural Network (CNN) based methods have shown great promises, they are difficult to use in practice due to their high computational complexity and lack of transferability. Here, we propose a highly efficient CNN-based model that maintains fast computations similar to the knowledge-driven methods without excessive hardware requirements such as GPUs. We create a training dataset using FocusPath which encompasses diverse tissue slides across nine different stain colors, where the stain diversity greatly helps the model to learn diverse color spectrum and tissue structures. In our attempt to reduce the CNN complexity, we find with surprise that even trimming down the CNN to the minimal level, it still achieves a highly competitive performance. We introduce a novel comprehensive evaluation dataset, the largest of its kind, annotated and compiled from TCGA repository for model assessment and comparison, for which the proposed method exhibits superior precision-speed trade-off when compared with existing knowledge-driven and data-driven FQA approaches.},
  isbn = {978-3-030-59722-1},
  langid = {english},
  keywords = {Deep learning,Digital pathology,Focus Quality Assessment,out of focus detection,Out-of-focus,Pathology,related work,Whole Slide Image (WSI)},
  file = {/var/home/hannes/Zotero/storage/M2PBJBHU/Wang et al. - 2020 - FocusLiteNN High Efficiency Focus Quality Assessm.pdf}
}

@article{xiang2021autofocus,
  title = {Autofocus of Whole Slide Imaging Based on Convolution and Recurrent Neural Networks},
  author = {Xiang, Yao and He, Zhujun and Liu, Qing and Chen, Jialin and Liang, Yixiong},
  date = {2021-01},
  journaltitle = {Ultramicroscopy},
  shortjournal = {Ultramicroscopy},
  volume = {220},
  pages = {113146},
  issn = {03043991},
  doi = {10/gnpqnz},
  abstract = {During the process of whole slide imaging, it is necessary to focus thousands of fields of view to obtain a high-quality image. To make the focusing procedure efficient and effective, we propose a novel autofocus algorithm for whole slide imaging. It is based on convolution and recurrent neural networks to predict the out-of-focus distance and subsequently update the focus location of the camera lens in an iterative manner. More specifically, we train a convolution neural network to extract focus information in the form of a focus feature vector. In order to make the prediction more accurate, we apply a recurrent neural network to combine focus information from previous search iteration and current search iteration to form a feature aggregation vector. This vector contains more focus information than the previous one and is subsequently used to predict the out-of-focus distance. Our experiments indicate that our proposed autofocus algorithm is able to rapidly determine the optimal in-focus image. The code is available at https://github.com/hezhujun/autofocus-rnn.},
  langid = {english},
  keywords = {autofocus,autofocus-rnn,related work},
  file = {/var/home/hannes/Zotero/storage/PXVKGKHJ/Xiang et al. - 2021 - Autofocus of whole slide imaging based on convolut.pdf}
}

@inproceedings{zagoruyko2016wide,
  title = {Wide {{Residual Networks}}},
  booktitle = {Proceedings of the {{British Machine Vision Conference}} 2016},
  author = {Zagoruyko, Sergey and Komodakis, Nikos},
  date = {2016},
  eprint = {1605.07146},
  eprinttype = {arxiv},
  publisher = {{BMVA Press}},
  location = {{York, United Kingdom}},
  abstract = {Deep residual networks were shown to be able to scale up to thousands of layers and still have improving performance. However, each fraction of a percent of improved accuracy costs nearly doubling the number of layers, and so training very deep residual networks has a problem of diminishing feature reuse, which makes these networks very slow to train. To tackle these problems, in this paper we conduct a detailed experimental study on the architecture of ResNet blocks, based on which we propose a novel architecture where we decrease depth and increase width of residual networks. We call the resulting network structures wide residual networks (WRNs) and show that these are far superior over their commonly used thin and very deep counterparts. For example, we demonstrate that even a simple 16-layer-deep wide residual network outperforms in accuracy and efficiency all previous deep residual networks, including thousand-layerdeep networks, achieving new state-of-the-art results on CIFAR, SVHN, COCO, and significant improvements on ImageNet. Our code and models are available at https: //github.com/szagoruyko/wide-residual-networks.},
  archiveprefix = {arXiv},
  eventtitle = {British {{Machine Vision Conference}}},
  isbn = {1-901725-59-6},
  langid = {english},
  keywords = {⛔ No DOI found,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing,model,resnet,resnet-wide},
  file = {/var/home/hannes/Zotero/storage/FBD326AI/Zagoruyko and Komodakis - 2017 - Wide Residual Networks.pdf}
}

@preamble{ "\ifdefined\DeclarePrefChars\DeclarePrefChars{'’-}\else\fi " }

